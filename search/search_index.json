{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"amba-analysis-streams-api REST API for stream analysis platform endpoints: api docs The implementation of the API is based on FastAPI [^1], a python high-performance framework that is running in a docker container. There are four primary REST endpoints: publications, authors, field of study, and statistics. Further, a system check is available to check if the API and the system are working as expected. The API is automatically generating interactive documentation with open API JSON. All responses are timed; these times are added to the result and stored in the InfluxDB. The calculated times allow monitoring and identifying slow queries. Further, all results over 1000 Bytes are being compressed with GZIP, reducing the network data. The PostgreSQL access is implemented using SQLAlchemy[^2] and InfluxDB using their respective clients. The \u201cpublications\u201d endpoint allows querying publications, trending publications, and trending publications for a specific author or field of study and retrieving a single publication. Trending publications can be retrieved with offset, order, limit, search, and for a specific duration to allow them to be ideally queried for a table loading the data as needed. Fields of study are similar to authors in aggregating publications. Their endpoints allow retrieving single elements as well as data suited for tables. Further access to trending fields of studies and authors are possible. The \u201cstats\u201d endpoint allows querying data extending the trending table data to analyze publications further. It allows access to data from PostgreSQL and data from the influx specifically for a given duration. Nearly all stats endpoints offer an option to query data for either a publication, an author, or a field of study. The API is adjusted to the database scheme and will not query the InfluxDB for slow high cardinality queries. Instead, it uses PostgreSQL with optimized InfluxDB queries and specific buckets to keep the response times low and responsibility high. [^1]: https://fastapi.tiangolo.com/ ; accessed 10-November-2021 [^2]: https://www.sqlalchemy.org/ ; accessed 10-November-2021 Monitoring using InfluxDB - every response will be saved as: point = { \"measurement\": \"response_time\", \"tags\": { \"path\": request.url.path }, \"fields\": { 'response_time': int(process_time * 1000), 'url': str(request.url) }, \"time\": datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')} show api response count per 5m in range from(bucket: \"api_monitor\") |> range(start: v.timeRangeStart, stop: v.timeRangeStop) |> filter(fn: (r) => r[\"_measurement\"] == \"response_time\") |> filter(fn: (r) => r[\"_field\"] == \"response_time\") |> group() |> aggregateWindow(every: 5m, fn: count, createEmpty: false) |> yield(name: \"mean\")","title":"Home"},{"location":"#amba-analysis-streams-api","text":"REST API for stream analysis platform","title":"amba-analysis-streams-api"},{"location":"#endpoints","text":"api docs The implementation of the API is based on FastAPI [^1], a python high-performance framework that is running in a docker container. There are four primary REST endpoints: publications, authors, field of study, and statistics. Further, a system check is available to check if the API and the system are working as expected. The API is automatically generating interactive documentation with open API JSON. All responses are timed; these times are added to the result and stored in the InfluxDB. The calculated times allow monitoring and identifying slow queries. Further, all results over 1000 Bytes are being compressed with GZIP, reducing the network data. The PostgreSQL access is implemented using SQLAlchemy[^2] and InfluxDB using their respective clients. The \u201cpublications\u201d endpoint allows querying publications, trending publications, and trending publications for a specific author or field of study and retrieving a single publication. Trending publications can be retrieved with offset, order, limit, search, and for a specific duration to allow them to be ideally queried for a table loading the data as needed. Fields of study are similar to authors in aggregating publications. Their endpoints allow retrieving single elements as well as data suited for tables. Further access to trending fields of studies and authors are possible. The \u201cstats\u201d endpoint allows querying data extending the trending table data to analyze publications further. It allows access to data from PostgreSQL and data from the influx specifically for a given duration. Nearly all stats endpoints offer an option to query data for either a publication, an author, or a field of study. The API is adjusted to the database scheme and will not query the InfluxDB for slow high cardinality queries. Instead, it uses PostgreSQL with optimized InfluxDB queries and specific buckets to keep the response times low and responsibility high. [^1]: https://fastapi.tiangolo.com/ ; accessed 10-November-2021 [^2]: https://www.sqlalchemy.org/ ; accessed 10-November-2021 Monitoring using InfluxDB - every response will be saved as: point = { \"measurement\": \"response_time\", \"tags\": { \"path\": request.url.path }, \"fields\": { 'response_time': int(process_time * 1000), 'url': str(request.url) }, \"time\": datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')} show api response count per 5m in range from(bucket: \"api_monitor\") |> range(start: v.timeRangeStart, stop: v.timeRangeStop) |> filter(fn: (r) => r[\"_measurement\"] == \"response_time\") |> filter(fn: (r) => r[\"_field\"] == \"response_time\") |> group() |> aggregateWindow(every: 5m, fn: count, createEmpty: false) |> yield(name: \"mean\")","title":"endpoints:"},{"location":"main_ref/","text":"add_process_time_header ( request , call_next ) async store process time in the influxdb for statistics Source code in app/main.py @app . middleware ( \"http\" ) async def add_process_time_header ( request : Request , call_next ): \"\"\" store process time in the influxdb for statistics \"\"\" start_time = time . time () response = await call_next ( request ) process_time = time . time () - start_time point = { \"measurement\" : \"response_time\" , \"tags\" : { \"path\" : request . url . path }, \"fields\" : { 'response_time' : int ( process_time * 1000 ), 'url' : str ( request . url ) }, \"time\" : datetime . utcnow () . strftime ( '%Y-%m- %d T%H:%M:%SZ' )} print ( point ) write_api . write ( 'api_monitor' , org , [ point ]) return response is_api_available () Checks if the api is running as expected. It returns 'ok' normally, if there is to little data in the last few minutes it will return 'not running' Source code in app/main.py @app . get ( \"/api/trend/available\" , response_description = \"available\" , summary = \"Check if api is available.\" ) def is_api_available (): \"\"\" Checks if the api is running as expected. It returns 'ok' normally, if there is to little data in the last few minutes it will return 'not running' \"\"\" return JSONResponse ( content = system_running_check ( query_api ))","title":"main"},{"location":"main_ref/#main.add_process_time_header","text":"store process time in the influxdb for statistics Source code in app/main.py @app . middleware ( \"http\" ) async def add_process_time_header ( request : Request , call_next ): \"\"\" store process time in the influxdb for statistics \"\"\" start_time = time . time () response = await call_next ( request ) process_time = time . time () - start_time point = { \"measurement\" : \"response_time\" , \"tags\" : { \"path\" : request . url . path }, \"fields\" : { 'response_time' : int ( process_time * 1000 ), 'url' : str ( request . url ) }, \"time\" : datetime . utcnow () . strftime ( '%Y-%m- %d T%H:%M:%SZ' )} print ( point ) write_api . write ( 'api_monitor' , org , [ point ]) return response","title":"add_process_time_header()"},{"location":"main_ref/#main.is_api_available","text":"Checks if the api is running as expected. It returns 'ok' normally, if there is to little data in the last few minutes it will return 'not running' Source code in app/main.py @app . get ( \"/api/trend/available\" , response_description = \"available\" , summary = \"Check if api is available.\" ) def is_api_available (): \"\"\" Checks if the api is running as expected. It returns 'ok' normally, if there is to little data in the last few minutes it will return 'not running' \"\"\" return JSONResponse ( content = system_running_check ( query_api ))","title":"is_api_available()"},{"location":"daos/author_ref/","text":"get_authors ( session , offset = 0 , limit = 10 , sort = 'id' , order = 'asc' , search = '' ) get authors from postresql Source code in daos/author.py def get_authors ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'id' , order : str = 'asc' , search : str = '' ): \"\"\" get authors from postresql \"\"\" q = \"\"\" SELECT a.*, array_agg('{name: \"' || p.title || '\", doi: \"' || p.doi || '\", date: \"' || p.pub_date || '\"}') FROM author a JOIN publication_author pfos on pfos.author_id = a.id JOIN publication p on p.doi = pfos.publication_doi \"\"\" qs = \"\"\" WHERE a.name ILIKE '%:search%' \"\"\" qb = ' GROUP BY a.id ORDER BY ' sortable = [ 'id' ] if sort in sortable : if sort == 'id' : qb += 'a.id ' else : qb += 'a.id ' # only allow set string to avoid sql injection order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall () get_trending_authors ( session , offset = 0 , limit = 10 , sort = 'score' , order = 'asc' , search = '' , duration = 'currently' ) get trending authors from postgresql Source code in daos/author.py def get_trending_authors ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'asc' , search : str = '' , duration : str = \"currently\" ): \"\"\" get trending authors from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, *, count(*) OVER() AS total_count FROM ( SELECT a.id, a.name, count(t.publication_doi) as pub_count, SUM(t.score) as score, SUM(count) as count, AVG(mean_sentiment) as mean_sentiment, SUM(sum_followers) as sum_followers, AVG(abstract_difference) as abstract_difference, AVG(mean_age) as mean_age, AVG(mean_length) as mean_length, AVG(mean_questions) as mean_questions, AVG(mean_exclamations) as mean_exclamations, AVG(mean_bot_rating) as mean_bot_rating, AVG(projected_change) as projected_change, AVG(trending) as trending, AVG(ema) as ema, AVG(kama) as kama, AVG(ker) as ker, AVG(mean_score) as mean_score, AVG(stddev) as stddev FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_author pa on p.doi = pa.publication_doi JOIN author a on a.id = pa.author_id WHERE duration = :duration \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'pub_count' ] qb = ' GROUP BY a.id) t ORDER BY ' qs = \"\"\" AND a.name ILIKE :search \"\"\" if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall () retrieve_author ( session , id , with_pubs = False ) get author data for from postresql id : author id with_pubs : include publication Source code in daos/author.py def retrieve_author ( session : Session , id , with_pubs = False ): \"\"\" get author data for from postresql - **id**: author id - **with_pubs**: include publication \"\"\" params = { 'id' : id } f = text ( \"\"\"SELECT name FROM author WHERE id=:id\"\"\" ) f = f . bindparams ( bindparam ( 'id' )) a = session . execute ( f , params ) . fetchall () result = { 'author' : a [ 0 ]} if with_pubs : p = text ( \"\"\" SELECT p.* FROM publication_author pf JOIN publication p on p.doi = pf.publication_doi WHERE pf.author_id=:id\"\"\" ) p = p . bindparams ( bindparam ( 'id' )) pubs = session . execute ( p , params ) . fetchall () result [ 'publications' ] = pubs return result","title":"author"},{"location":"daos/author_ref/#daos.author.get_authors","text":"get authors from postresql Source code in daos/author.py def get_authors ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'id' , order : str = 'asc' , search : str = '' ): \"\"\" get authors from postresql \"\"\" q = \"\"\" SELECT a.*, array_agg('{name: \"' || p.title || '\", doi: \"' || p.doi || '\", date: \"' || p.pub_date || '\"}') FROM author a JOIN publication_author pfos on pfos.author_id = a.id JOIN publication p on p.doi = pfos.publication_doi \"\"\" qs = \"\"\" WHERE a.name ILIKE '%:search%' \"\"\" qb = ' GROUP BY a.id ORDER BY ' sortable = [ 'id' ] if sort in sortable : if sort == 'id' : qb += 'a.id ' else : qb += 'a.id ' # only allow set string to avoid sql injection order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall ()","title":"get_authors()"},{"location":"daos/author_ref/#daos.author.get_trending_authors","text":"get trending authors from postgresql Source code in daos/author.py def get_trending_authors ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'asc' , search : str = '' , duration : str = \"currently\" ): \"\"\" get trending authors from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, *, count(*) OVER() AS total_count FROM ( SELECT a.id, a.name, count(t.publication_doi) as pub_count, SUM(t.score) as score, SUM(count) as count, AVG(mean_sentiment) as mean_sentiment, SUM(sum_followers) as sum_followers, AVG(abstract_difference) as abstract_difference, AVG(mean_age) as mean_age, AVG(mean_length) as mean_length, AVG(mean_questions) as mean_questions, AVG(mean_exclamations) as mean_exclamations, AVG(mean_bot_rating) as mean_bot_rating, AVG(projected_change) as projected_change, AVG(trending) as trending, AVG(ema) as ema, AVG(kama) as kama, AVG(ker) as ker, AVG(mean_score) as mean_score, AVG(stddev) as stddev FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_author pa on p.doi = pa.publication_doi JOIN author a on a.id = pa.author_id WHERE duration = :duration \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'pub_count' ] qb = ' GROUP BY a.id) t ORDER BY ' qs = \"\"\" AND a.name ILIKE :search \"\"\" if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall ()","title":"get_trending_authors()"},{"location":"daos/author_ref/#daos.author.retrieve_author","text":"get author data for from postresql id : author id with_pubs : include publication Source code in daos/author.py def retrieve_author ( session : Session , id , with_pubs = False ): \"\"\" get author data for from postresql - **id**: author id - **with_pubs**: include publication \"\"\" params = { 'id' : id } f = text ( \"\"\"SELECT name FROM author WHERE id=:id\"\"\" ) f = f . bindparams ( bindparam ( 'id' )) a = session . execute ( f , params ) . fetchall () result = { 'author' : a [ 0 ]} if with_pubs : p = text ( \"\"\" SELECT p.* FROM publication_author pf JOIN publication p on p.doi = pf.publication_doi WHERE pf.author_id=:id\"\"\" ) p = p . bindparams ( bindparam ( 'id' )) pubs = session . execute ( p , params ) . fetchall () result [ 'publications' ] = pubs return result","title":"retrieve_author()"},{"location":"daos/database_ref/","text":"Database Setup get configs from enviroment and initialize the connections to - postgresql - influxdb","title":"database"},{"location":"daos/field_of_study_ref/","text":"get_fields_of_study ( session , offset = 0 , limit = 10 , sort = 'id' , order = 'asc' , search = '' ) retrieve fields of study from postgres Source code in daos/field_of_study.py def get_fields_of_study ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'id' , order : str = 'asc' , search : str = '' ): \"\"\" retrieve fields of study from postgres \"\"\" q = \"\"\" SELECT fos.*, array_agg('{name: \"' || p.title || '\", doi: \"' || p.doi || '\", date: \"' || p.pub_date || '\"}') FROM field_of_study fos JOIN publication_field_of_study pfos on pfos.field_of_study_id = fos.id JOIN publication p on p.doi = pfos.publication_doi \"\"\" qs = \"\"\" WHERE fos.name ILIKE '%:search%' \"\"\" qb = ' GROUP BY fos.id ORDER BY ' sortable = [ 'id' ] if sort in sortable : if sort == 'id' : qb += 'fos.id ' else : qb += 'fos.id ' # only allow set string to avoid sql injection order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall () get_trending_fields_of_study ( session , offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , search = '' , duration = 'currently' ) retrieve field of study from postgres Source code in daos/field_of_study.py def get_trending_fields_of_study ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = 'currently' ): \"\"\" retrieve field of study from postgres \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, *, count(*) OVER() AS total_count FROM ( SELECT fos.id, fos.name, count(t.publication_doi) as pub_count, SUM(t.score) as score, SUM(count) as count, AVG(mean_sentiment) as mean_sentiment, SUM(sum_followers) as sum_followers, AVG(abstract_difference) as abstract_difference, AVG(mean_age) as mean_age, AVG(mean_length) as mean_length, AVG(mean_questions) as mean_questions, AVG(mean_exclamations) as mean_exclamations, AVG(mean_bot_rating) as mean_bot_rating, AVG(projected_change) as projected_change, AVG(trending) as trending, AVG(ema) as ema, AVG(kama) as kama, AVG(ker) as ker, AVG(mean_score) as mean_score, AVG(stddev) as stddev FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi JOIN field_of_study fos on fos.id = pfos.field_of_study_id WHERE duration = :duration \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'pub_count' ] qb = ' GROUP BY fos.id) t ORDER BY ' qs = \"\"\" AND fos.name ILIKE :search \"\"\" if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall () retrieve_field_of_study ( session , id , with_pubs = False ) retrieve field of study from postgres Source code in daos/field_of_study.py def retrieve_field_of_study ( session : Session , id , with_pubs = False ): \"\"\" retrieve field of study from postgres \"\"\" params = { 'id' : id } f = text ( \"\"\"SELECT name FROM field_of_study WHERE id=:id\"\"\" ) f = f . bindparams ( bindparam ( 'id' )) fos = session . execute ( f , params ) . fetchall () result = { 'fields_of_study' : fos [ 0 ]} if with_pubs : p = text ( \"\"\" SELECT p.* FROM publication_field_of_study pf JOIN publication p on p.doi = pf.publication_doi WHERE pf.field_of_study_id=:id\"\"\" ) p = p . bindparams ( bindparam ( 'id' )) pubs = session . execute ( p , params ) . fetchall () result [ 'publications' ] = pubs return result","title":"field_of_study"},{"location":"daos/field_of_study_ref/#daos.field_of_study.get_fields_of_study","text":"retrieve fields of study from postgres Source code in daos/field_of_study.py def get_fields_of_study ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'id' , order : str = 'asc' , search : str = '' ): \"\"\" retrieve fields of study from postgres \"\"\" q = \"\"\" SELECT fos.*, array_agg('{name: \"' || p.title || '\", doi: \"' || p.doi || '\", date: \"' || p.pub_date || '\"}') FROM field_of_study fos JOIN publication_field_of_study pfos on pfos.field_of_study_id = fos.id JOIN publication p on p.doi = pfos.publication_doi \"\"\" qs = \"\"\" WHERE fos.name ILIKE '%:search%' \"\"\" qb = ' GROUP BY fos.id ORDER BY ' sortable = [ 'id' ] if sort in sortable : if sort == 'id' : qb += 'fos.id ' else : qb += 'fos.id ' # only allow set string to avoid sql injection order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall ()","title":"get_fields_of_study()"},{"location":"daos/field_of_study_ref/#daos.field_of_study.get_trending_fields_of_study","text":"retrieve field of study from postgres Source code in daos/field_of_study.py def get_trending_fields_of_study ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = 'currently' ): \"\"\" retrieve field of study from postgres \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, *, count(*) OVER() AS total_count FROM ( SELECT fos.id, fos.name, count(t.publication_doi) as pub_count, SUM(t.score) as score, SUM(count) as count, AVG(mean_sentiment) as mean_sentiment, SUM(sum_followers) as sum_followers, AVG(abstract_difference) as abstract_difference, AVG(mean_age) as mean_age, AVG(mean_length) as mean_length, AVG(mean_questions) as mean_questions, AVG(mean_exclamations) as mean_exclamations, AVG(mean_bot_rating) as mean_bot_rating, AVG(projected_change) as projected_change, AVG(trending) as trending, AVG(ema) as ema, AVG(kama) as kama, AVG(ker) as ker, AVG(mean_score) as mean_score, AVG(stddev) as stddev FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi JOIN field_of_study fos on fos.id = pfos.field_of_study_id WHERE duration = :duration \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'pub_count' ] qb = ' GROUP BY fos.id) t ORDER BY ' qs = \"\"\" AND fos.name ILIKE :search \"\"\" if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall ()","title":"get_trending_fields_of_study()"},{"location":"daos/field_of_study_ref/#daos.field_of_study.retrieve_field_of_study","text":"retrieve field of study from postgres Source code in daos/field_of_study.py def retrieve_field_of_study ( session : Session , id , with_pubs = False ): \"\"\" retrieve field of study from postgres \"\"\" params = { 'id' : id } f = text ( \"\"\"SELECT name FROM field_of_study WHERE id=:id\"\"\" ) f = f . bindparams ( bindparam ( 'id' )) fos = session . execute ( f , params ) . fetchall () result = { 'fields_of_study' : fos [ 0 ]} if with_pubs : p = text ( \"\"\" SELECT p.* FROM publication_field_of_study pf JOIN publication p on p.doi = pf.publication_doi WHERE pf.field_of_study_id=:id\"\"\" ) p = p . bindparams ( bindparam ( 'id' )) pubs = session . execute ( p , params ) . fetchall () result [ 'publications' ] = pubs return result","title":"retrieve_field_of_study()"},{"location":"daos/publication_ref/","text":"get_publications ( session , offset = 0 , limit = 10 , sort = 'id' , order = 'asc' , search = '' ) get publications from postgresql Source code in daos/publication.py def get_publications ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'id' , order : str = 'asc' , search : str = '' ): \"\"\" get publications from postgresql \"\"\" q = \"\"\" SELECT p.*, array_agg(a.id || ': ' || a.name), array_agg(fos.id || ': ' || fos.name), count(*) OVER() AS total_count FROM publication p JOIN publication_author pa on p.doi = pa.publication_doi JOIN author as a on pa.author_id = a.id JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi JOIN field_of_study fos on pfos.field_of_study_id = fos.id \"\"\" qs = \"\"\" WHERE p.title ILIKE :search \"\"\" qb = ' GROUP BY p.id ' sortable = [ 'id' ] if sort in sortable : if sort == 'id' : qb += ' ORDER BY ' qb += 'p.id ' else : qb += ' ORDER BY ' qb += 'p.id ' return query_bottom ( session , q , qs , qb , order , limit , offset , search ) get_trending_covid_publications ( session , offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , duration = 'currently' , search = '' ) get trending covid publications from postgresql Source code in daos/publication.py def get_trending_covid_publications ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending covid publications from postgresql \"\"\" q = \"\"\" SELECT *, count(*) OVER() AS total_count FROM trending_covid_papers WHERE duration = :duration \"\"\" qs = \"\"\" AND title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall () get_trending_publications ( session , offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , duration = 'currently' , search = '' ) get trending publications from postgresql Source code in daos/publication.py def get_trending_publications ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending publications from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, p.*, t.score, count, mean_sentiment, sum_followers, abstract_difference, mean_age, mean_length, mean_questions, mean_exclamations, mean_bot_rating, projected_change, trending, ema, kama, ker, mean_score, stddev, count(*) OVER() AS total_count FROM trending t JOIN publication p on p.doi = t.publication_doi WHERE duration = :duration \"\"\" qs = \"\"\" AND p.title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall () get_trending_publications_for_author ( author_id , session , offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , duration = 'currently' , search = '' ) get trending publications for a given author from postgresql Source code in daos/publication.py def get_trending_publications_for_author ( author_id : int , session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending publications for a given author from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, p.*, t.score, count, mean_sentiment, sum_followers, abstract_difference, mean_age, mean_length, mean_questions, mean_exclamations, mean_bot_rating, projected_change, trending, ema, kama, ker, mean_score, stddev, count(*) OVER() AS total_count FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_author pa on p.doi = pa.publication_doi WHERE duration = :duration AND author_id = :author_id \"\"\" qs = \"\"\" AND p.title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset , 'author_id' : author_id } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'author_id' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'author_id' )) return session . execute ( s , params ) . fetchall () get_trending_publications_for_field_of_study ( fos_id , session , offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , duration = 'currently' , search = '' ) get trending publications for a given field of study from postgresql Source code in daos/publication.py def get_trending_publications_for_field_of_study ( fos_id : int , session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending publications for a given field of study from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, p.*, t.score, count, mean_sentiment, sum_followers, abstract_difference, mean_age, mean_length, mean_questions, mean_exclamations, mean_bot_rating, projected_change, trending, ema, kama, ker, mean_score, stddev, count(*) OVER() AS total_count FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi WHERE duration = :duration AND field_of_study_id = :fos_id \"\"\" qs = \"\"\" AND p.title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset , 'fos_id' : fos_id } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'fos_id' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'fos_id' )) return session . execute ( s , params ) . fetchall () query_bottom ( session , q , qs , qb , order , limit , offset , search ) query helper adding limit, sorting and search (postgresql only) Source code in daos/publication.py def query_bottom ( session , q , qs , qb , order , limit , offset , search ): \"\"\" query helper adding limit, sorting and search (postgresql only) \"\"\" order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb print ( q ) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb print ( q ) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall () retrieve_publication ( session , doi , duration = 'currently' ) get publication data including rank, fos, sources, authors from postgresql Source code in daos/publication.py def retrieve_publication ( session : Session , doi , duration : str = \"currently\" ): \"\"\" get publication data including rank, fos, sources, authors from postgresql \"\"\" pub = session . query ( Publication ) . filter_by ( doi = doi ) . all () a = text ( \"\"\"SELECT id, name FROM publication_author as p JOIN author as a on (a.id = p.author_id) WHERE p.publication_doi=:doi\"\"\" ) params = { 'doi' : doi , } a = a . bindparams ( bindparam ( 'doi' )) authors = session . execute ( a , params ) . fetchall () f = text ( \"\"\"SELECT id, name FROM publication_field_of_study as p JOIN field_of_study as a on (a.id = p.field_of_study_id) WHERE p.publication_doi=:doi\"\"\" ) f = f . bindparams ( bindparam ( 'doi' )) fos = session . execute ( f , params ) . fetchall () s = text ( \"\"\"SELECT id, title, url, license FROM publication_source as p JOIN source as a on (a.id = p.source_id) WHERE p.publication_doi=:doi\"\"\" ) s = s . bindparams ( bindparam ( 'doi' )) sources = session . execute ( s , params ) . fetchall () query = \"\"\" SELECT trending_ranking FROM (SELECT ROW_NUMBER() OVER (ORDER BY score DESC) as trending_ranking, publication_doi FROM trending t WHERE duration = :duration) t WHERE publication_doi = :doi \"\"\" params = { 'duration' : duration , 'doi' : doi } s = text ( query ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'doi' )) rank = session . execute ( s , params ) . fetchone () if rank : r = rank [ 0 ] else : r = None return { 'publication' : pub , 'authors' : authors , 'fields_of_study' : fos , 'sources' : sources , 'trending_ranking' : r }","title":"publication"},{"location":"daos/publication_ref/#daos.publication.get_publications","text":"get publications from postgresql Source code in daos/publication.py def get_publications ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'id' , order : str = 'asc' , search : str = '' ): \"\"\" get publications from postgresql \"\"\" q = \"\"\" SELECT p.*, array_agg(a.id || ': ' || a.name), array_agg(fos.id || ': ' || fos.name), count(*) OVER() AS total_count FROM publication p JOIN publication_author pa on p.doi = pa.publication_doi JOIN author as a on pa.author_id = a.id JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi JOIN field_of_study fos on pfos.field_of_study_id = fos.id \"\"\" qs = \"\"\" WHERE p.title ILIKE :search \"\"\" qb = ' GROUP BY p.id ' sortable = [ 'id' ] if sort in sortable : if sort == 'id' : qb += ' ORDER BY ' qb += 'p.id ' else : qb += ' ORDER BY ' qb += 'p.id ' return query_bottom ( session , q , qs , qb , order , limit , offset , search )","title":"get_publications()"},{"location":"daos/publication_ref/#daos.publication.get_trending_covid_publications","text":"get trending covid publications from postgresql Source code in daos/publication.py def get_trending_covid_publications ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending covid publications from postgresql \"\"\" q = \"\"\" SELECT *, count(*) OVER() AS total_count FROM trending_covid_papers WHERE duration = :duration \"\"\" qs = \"\"\" AND title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall ()","title":"get_trending_covid_publications()"},{"location":"daos/publication_ref/#daos.publication.get_trending_publications","text":"get trending publications from postgresql Source code in daos/publication.py def get_trending_publications ( session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending publications from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, p.*, t.score, count, mean_sentiment, sum_followers, abstract_difference, mean_age, mean_length, mean_questions, mean_exclamations, mean_bot_rating, projected_change, trending, ema, kama, ker, mean_score, stddev, count(*) OVER() AS total_count FROM trending t JOIN publication p on p.doi = t.publication_doi WHERE duration = :duration \"\"\" qs = \"\"\" AND p.title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall ()","title":"get_trending_publications()"},{"location":"daos/publication_ref/#daos.publication.get_trending_publications_for_author","text":"get trending publications for a given author from postgresql Source code in daos/publication.py def get_trending_publications_for_author ( author_id : int , session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending publications for a given author from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, p.*, t.score, count, mean_sentiment, sum_followers, abstract_difference, mean_age, mean_length, mean_questions, mean_exclamations, mean_bot_rating, projected_change, trending, ema, kama, ker, mean_score, stddev, count(*) OVER() AS total_count FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_author pa on p.doi = pa.publication_doi WHERE duration = :duration AND author_id = :author_id \"\"\" qs = \"\"\" AND p.title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset , 'author_id' : author_id } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'author_id' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'author_id' )) return session . execute ( s , params ) . fetchall ()","title":"get_trending_publications_for_author()"},{"location":"daos/publication_ref/#daos.publication.get_trending_publications_for_field_of_study","text":"get trending publications for a given field of study from postgresql Source code in daos/publication.py def get_trending_publications_for_field_of_study ( fos_id : int , session : Session , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , duration : str = \"currently\" , search : str = '' ): \"\"\" get trending publications for a given field of study from postgresql \"\"\" q = \"\"\" SELECT ROW_NUMBER () OVER (ORDER BY score DESC) as trending_ranking, p.*, t.score, count, mean_sentiment, sum_followers, abstract_difference, mean_age, mean_length, mean_questions, mean_exclamations, mean_bot_rating, projected_change, trending, ema, kama, ker, mean_score, stddev, count(*) OVER() AS total_count FROM trending t JOIN publication p on p.doi = t.publication_doi JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi WHERE duration = :duration AND field_of_study_id = :fos_id \"\"\" qs = \"\"\" AND p.title ILIKE :search \"\"\" sortable = [ 'trending_ranking' , 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' , 'year' , 'citation_count' ] qb = ' ORDER BY ' if sort in sortable : qb += sort + ' ' else : qb += 'score ' order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'duration' : duration , 'limit' : limit , 'offset' : offset , 'fos_id' : fos_id } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'fos_id' ), bindparam ( 'search' )) else : q += qb # print(q) s = text ( q ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'fos_id' )) return session . execute ( s , params ) . fetchall ()","title":"get_trending_publications_for_field_of_study()"},{"location":"daos/publication_ref/#daos.publication.query_bottom","text":"query helper adding limit, sorting and search (postgresql only) Source code in daos/publication.py def query_bottom ( session , q , qs , qb , order , limit , offset , search ): \"\"\" query helper adding limit, sorting and search (postgresql only) \"\"\" order_sql = ' ASC ' if order == 'desc' : order_sql = ' DESC ' qb += order_sql qb += \"\"\" LIMIT :limit OFFSET :offset \"\"\" params = { 'limit' : limit , 'offset' : offset } if len ( search ) > 3 : params [ 'search' ] = '%' + search + '%' q += qs q += qb print ( q ) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' ), bindparam ( 'search' )) else : q += qb print ( q ) s = text ( q ) . bindparams ( bindparam ( 'limit' ), bindparam ( 'offset' )) return session . execute ( s , params ) . fetchall ()","title":"query_bottom()"},{"location":"daos/publication_ref/#daos.publication.retrieve_publication","text":"get publication data including rank, fos, sources, authors from postgresql Source code in daos/publication.py def retrieve_publication ( session : Session , doi , duration : str = \"currently\" ): \"\"\" get publication data including rank, fos, sources, authors from postgresql \"\"\" pub = session . query ( Publication ) . filter_by ( doi = doi ) . all () a = text ( \"\"\"SELECT id, name FROM publication_author as p JOIN author as a on (a.id = p.author_id) WHERE p.publication_doi=:doi\"\"\" ) params = { 'doi' : doi , } a = a . bindparams ( bindparam ( 'doi' )) authors = session . execute ( a , params ) . fetchall () f = text ( \"\"\"SELECT id, name FROM publication_field_of_study as p JOIN field_of_study as a on (a.id = p.field_of_study_id) WHERE p.publication_doi=:doi\"\"\" ) f = f . bindparams ( bindparam ( 'doi' )) fos = session . execute ( f , params ) . fetchall () s = text ( \"\"\"SELECT id, title, url, license FROM publication_source as p JOIN source as a on (a.id = p.source_id) WHERE p.publication_doi=:doi\"\"\" ) s = s . bindparams ( bindparam ( 'doi' )) sources = session . execute ( s , params ) . fetchall () query = \"\"\" SELECT trending_ranking FROM (SELECT ROW_NUMBER() OVER (ORDER BY score DESC) as trending_ranking, publication_doi FROM trending t WHERE duration = :duration) t WHERE publication_doi = :doi \"\"\" params = { 'duration' : duration , 'doi' : doi } s = text ( query ) . bindparams ( bindparam ( 'duration' ), bindparam ( 'doi' )) rank = session . execute ( s , params ) . fetchone () if rank : r = rank [ 0 ] else : r = None return { 'publication' : pub , 'authors' : authors , 'fields_of_study' : fos , 'sources' : sources , 'trending_ranking' : r }","title":"retrieve_publication()"},{"location":"daos/stats_ref/","text":"doi_filter_list ( doi_list , params ) influx helper adding a doi filter list (faster than array check in influx) Source code in daos/stats.py def doi_filter_list ( doi_list , params ): \"\"\" influx helper adding a doi filter list (faster than array check in influx) \"\"\" if doi_list : filter_string = \"\"\" |> filter(fn: (r) => \"\"\" i = 0 for doi in doi_list : filter_string += 'r[\"doi\"] == _doi_nr_' + str ( i ) + ' or ' params [ '_doi_nr_' + str ( i )] = doi i += 1 filter_string = filter_string [: - 4 ] + ')' return { \"string\" : filter_string , \"params\" : params } return { \"string\" : '' , \"params\" : params } fetch_with_doi_filter ( session , query , doi ) postresql helper to add a doi filter Source code in daos/stats.py def fetch_with_doi_filter ( session : Session , query , doi ): \"\"\" postresql helper to add a doi filter \"\"\" if doi : query += 'WHERE publication_doi=:doi' params = { 'doi' : doi , } s = text ( query ) s = s . bindparams ( bindparam ( 'doi' )) return session . execute ( s , params ) . fetchall () s = text ( query ) return session . execute ( s ) . fetchall () get_discussion_data_list ( session , doi , limit , id , mode = 'publication' , dd_type = 'word' ) get discussion types with count from postgresql Source code in daos/stats.py def get_discussion_data_list ( session : Session , doi , limit , id , mode = \"publication\" , dd_type = \"word\" ): \"\"\" get discussion types with count from postgresql \"\"\" params = { 'type' : dd_type } if mode == \"fieldOfStudy\" : query = \"\"\"SELECT SUM(ddp.count) as count, dd.value FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_field_of_study as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = :type and value != 'und' and value != 'unknown' AND pfos.field_of_study_id=:id \"\"\" params [ 'id' ] = id elif mode == \"author\" : query = \"\"\"SELECT SUM(ddp.count) as count, dd.value FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_author as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = :type and value != 'und' and value != 'unknown' AND pfos.author_id=:id \"\"\" params [ 'id' ] = id else : # default publication query = \"\"\"SELECT SUM(ddp.count) as count, dd.value FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = :type and value != 'und' and value != 'unknown' \"\"\" extra = \"\"\" GROUP BY dd.id ORDER BY count DESC \"\"\" if limit : params [ 'limit' ] = limit extra += \" LIMIT :limit \" if doi : query += 'AND publication_doi=:doi ' params [ 'doi' ] = doi query += extra s = text ( query ) # print(query) # print(params) if 'doi' in params and 'limit' in params : # print('type, doi, limit') s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'doi' ), bindparam ( 'limit' )) elif 'doi' in params : # print('doi, type') s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'doi' )) elif 'limit' in params : # print('type, limit') s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'limit' )) else : # print('type') s = s . bindparams ( bindparam ( 'type' )) return session . execute ( s , params ) . fetchall () get_discussion_data_list_with_percentage ( session , doi , limit = 20 , min_percentage = 1 , dd_type = 'lang' ) get discussion types with count an percentage from postgresql Source code in daos/stats.py def get_discussion_data_list_with_percentage ( session : Session , doi , limit : int = 20 , min_percentage : float = 1 , dd_type = \"lang\" ): \"\"\" get discussion types with count an percentage from postgresql \"\"\" query = \"\"\" WITH result AS ( ( SELECT \"value\", SUM(count) as c, ROUND(SUM(count) / CAST(SUM(SUM(count)) OVER () AS FLOAT) * 1000) / 10 as p FROM (SELECT \"value\", \"count\" FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = :type and value != 'und' and value != 'unknown' \"\"\" extra1 = \"\"\") temp GROUP BY \"value\" ORDER BY c DESC LIMIT :limit ) UNION ( SELECT 'total' as \"value\", SUM(count) as c, 100 as p FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = :type and value != 'und' and value != 'unknown' \"\"\" extra2 = \"\"\" ) ) SELECT \"value\", c as count, p FROM result WHERE result.p >= :mp ORDER BY count DESC; \"\"\" params = { 'type' : dd_type , 'limit' : limit , 'mp' : min_percentage } if doi : query += ' AND publication_doi=:doi ' params [ 'doi' ] = doi query += extra1 if doi : query += ' AND publication_doi=:doi ' query += extra2 s = text ( query ) # print(query) # print(params) if 'doi' in params : s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'limit' ), bindparam ( 'mp' ), bindparam ( 'doi' )) else : s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'limit' ), bindparam ( 'mp' )) return session . execute ( s , params ) . fetchall () get_dois_for_author ( id , session , duration = 'currently' ) get dois for a given author from postgresql Source code in daos/stats.py def get_dois_for_author ( id , session : Session , duration = \"currently\" ): \"\"\" get dois for a given author from postgresql \"\"\" query = \"\"\" SELECT t.publication_doi FROM trending t JOIN publication_author pa on t.publication_doi = pa.publication_doi WHERE duration = :duration AND pa.author_id = :author_id; \"\"\" params = { 'duration' : duration , 'author_id' : id } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'author_id' )) rows = session . execute ( s , params ) . fetchall () result = [] for r in rows : result . append ( r [ 0 ]) # print(result) return result get_dois_for_field_of_study ( id , session , duration = 'currently' ) get dois for a given field of study from postgresql Source code in daos/stats.py def get_dois_for_field_of_study ( id , session : Session , duration = \"currently\" ): \"\"\" get dois for a given field of study from postgresql \"\"\" query = \"\"\" SELECT t.publication_doi FROM trending t JOIN publication_field_of_study pfos on t.publication_doi = pfos.publication_doi WHERE duration = :duration AND field_of_study_id = :fos_id; \"\"\" params = { 'duration' : duration , 'fos_id' : id } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'fos_id' )) rows = session . execute ( s , params ) . fetchall () result = [] for r in rows : result . append ( r [ 0 ]) # print(result) return result get_number_influx ( filter_obj , duration = 'currently' , field = 'score' ) get influx number for specific dois calculating, returns string query Source code in daos/stats.py def get_number_influx ( filter_obj , duration = \"currently\" , field = \"score\" ): \"\"\" get influx number for specific dois calculating, returns string query\"\"\" aggregation_field = { 'bot_rating' : 'mean' , 'contains_abstract_raw' : 'mean' , 'exclamations' : 'mean' , 'followers' : 'sum' , 'length' : 'mean' , 'questions' : 'mean' , 'score' : 'sum' , 'sentiment_raw' : 'mean' , \"pub_count\" : \"count\" , \"count\" : \"count\" } if field not in aggregation_field : # print('not in field') # return PlainTextResponse(content='field ' + field + ' not found') return None else : aggregator = aggregation_field [ field ] field_selector = field if field == \"count\" : field = \"temp_count\" # avoid trouble with renaming a function (count()) if duration == \"currently\" : field_selector = \"score\" else : aggregator = \"sum\" if field == \"pub_count\" : field_selector = 'score' query = field + ''' = from(bucket: _bucket) |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == \"''' + field_selector + '\")' if filter_obj : query += filter_obj [ 'string' ] query += \"\"\" |> group() \"\"\" if field == \"pub_count\" : query += '|> distinct(column: \"doi\")' if field == \"temp_count\" : field = \"count\" query += ''' |> ''' + aggregator + '''() |> keep(columns: [\"_value\", \"_time\", \"doi\"]) |> yield(name: \"''' + field + '''\") ''' return query get_numbers_influx ( query_api , dois , duration = 'currently' , fields = None ) get numbers from influx, switch between getting (total) and calculating (for dois) Source code in daos/stats.py def get_numbers_influx ( query_api , dois , duration = \"currently\" , fields = None ): \"\"\" get numbers from influx, switch between getting (total) and calculating (for dois) \"\"\" if fields is None : fields = [ \"score\" ] query = \"\"\" _start = _duration_time _stop = now() \"\"\" params = { '_duration_time' : trending_time_definition [ duration ][ 'duration' ], '_bucket' : trending_time_definition [ duration ][ 'name' ], } if dois : filter_obj = doi_filter_list ( dois , params ) # print('get numbers') for field in fields : query += get_number_influx ( filter_obj , duration , field ) tables = query_api . query ( query , params = filter_obj [ 'params' ]) else : # print('get task numbers') for field in fields : query += get_task_number_influx ( duration , field ) # print(query) tables = query_api . query ( query , params = params ) result = {} for table in tables : for record in table . records : result [ record [ 'result' ]] = record [ '_value' ] return result get_profile_information_avg ( session , duration = 'currently' ) get profile information avg, min, max from postgresql Source code in daos/stats.py def get_profile_information_avg ( session : Session , duration = \"currently\" ): \"\"\" get profile information avg, min, max from postgresql \"\"\" query = \"\"\" SELECT 'mean_score' as type, MIN(mean_score), MAX(mean_score), AVG(mean_score) FROM trending WHERE duration = :duration UNION SELECT 'mean_bot_rating' as type, MIN(mean_bot_rating), MAX(mean_bot_rating), AVG(mean_bot_rating) FROM trending WHERE duration = :duration UNION SELECT 'mean_sentiment' as type, MIN(mean_sentiment), MAX(mean_sentiment), AVG(mean_sentiment) FROM trending WHERE duration = :duration UNION SELECT 'sum_followers' as type, MIN(sum_followers), MAX(sum_followers), AVG(sum_followers) FROM trending WHERE duration = :duration UNION SELECT 'abstract_difference' as type, MIN(abstract_difference), MAX(abstract_difference), AVG(abstract_difference) FROM trending WHERE duration = :duration UNION SELECT 'mean_questions' as type, MIN(mean_questions), MAX(mean_questions), AVG(mean_questions) FROM trending WHERE duration = :duration UNION SELECT 'mean_exclamations' as type, MIN(mean_exclamations), MAX(mean_exclamations), AVG(mean_exclamations) FROM trending WHERE duration = :duration UNION SELECT 'mean_length' as type, MIN(mean_length), MAX(mean_length), AVG(mean_length) FROM trending WHERE duration = :duration; \"\"\" params = { 'duration' : duration , } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' )) rows = session . execute ( s , params ) . fetchall () result = { 'min' : {}, 'max' : {}, 'avg' : {}} for r in rows : result [ 'min' ][ r [ 0 ]] = r [ 1 ] result [ 'max' ][ r [ 0 ]] = r [ 2 ] result [ 'avg' ][ r [ 0 ]] = r [ 3 ] return result get_profile_information_for_doi ( session , doi , id , mode = 'publication' , duration = 'currently' ) get profile information for a doi, fieldOfStudy or Author Source code in daos/stats.py def get_profile_information_for_doi ( session : Session , doi , id , mode = \"publication\" , duration = \"currently\" ): \"\"\" get profile information for a doi, fieldOfStudy or Author\"\"\" query = \"\"\" SELECT AVG(mean_score) mean_score, AVG(abstract_difference) abstract_difference, AVG(mean_sentiment) mean_sentiment, \"\"\" if mode == \"publication\" : query += \"SUM(sum_followers) sum_followers,\" else : query += \"AVG(sum_followers) sum_followers,\" query += \"\"\" AVG(mean_length) mean_length, AVG(mean_questions) mean_questions, AVG(mean_exclamations) mean_exclamations, AVG(mean_bot_rating) mean_bot_rating FROM ( SELECT DISTINCT doi, mean_score, abstract_difference, mean_sentiment, sum_followers, mean_length, mean_questions, mean_exclamations, mean_bot_rating FROM trending t LEFT JOIN publication p on p.doi = t.publication_doi LEFT JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi LEFT JOIN publication_author pa on p.doi = pa.publication_doi WHERE duration = :duration \"\"\" params = { 'duration' : duration } if mode == \"publication\" : query += \"AND doi = :doi\" params [ 'doi' ] = doi if mode == \"author\" : query += \"AND author_id = :id\" params [ 'id' ] = id if mode == \"fieldOfStudy\" : query += \"AND field_of_study_id = :id\" params [ 'id' ] = id query += \" ) t\" s = text ( query ) # print(query) # print(params) if 'id' in params : s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'id' )) elif 'doi' in params : s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'doi' )) return session . execute ( s , params ) . fetchone () . _asdict () get_task_number_influx ( duration = 'currently' , field = 'score' ) get number from task (own bucket for total numbers, returns string query) Source code in daos/stats.py def get_task_number_influx ( duration = \"currently\" , field = \"score\" ): \"\"\" get number from task (own bucket for total numbers, returns string query) \"\"\" aggregation_field = { 'bot_rating' : 'mean' , 'contains_abstract_raw' : 'mean' , 'exclamations' : 'mean' , 'followers' : 'sum' , 'length' : 'mean' , 'questions' : 'mean' , 'score' : 'sum' , 'sentiment_raw' : 'mean' , \"pub_count\" : \"count\" , \"count\" : \"count\" } if field not in aggregation_field : # print('not in field') # return PlainTextResponse(content='field ' + field + ' not found') return None else : query = field + ''' = from(bucket: \"numbers\") |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"''' + duration + '''\") |> filter(fn: (r) => r[\"_field\"] == \"''' + field + '''\") |> last() |> keep(columns: [\"_value\", \"_time\", \"doi\"]) |> yield(name: \"''' + field + '''\") ''' return query get_top_n_dois ( query_api , duration = 'currently' , field = 'count' , n = 5 ) get top n dois by count, expensive query, influx db Source code in daos/stats.py def get_top_n_dois ( query_api , duration = \"currently\" , field = \"count\" , n = 5 ): \"\"\" get top n dois by count, expensive query, influx db \"\"\" if field == \"count\" : params = { '_window_time' : trending_time_definition [ duration ][ 'window_size' ], \"_duration_time\" : timedelta ( seconds =- trending_time_definition [ duration ][ 'duration' ] . total_seconds ()), '_bucket' : trending_time_definition [ duration ][ 'name' ], '_n' : n , } query = \"\"\" import \"experimental\" import \"date\" _start = experimental.subDuration(d: _duration_time, from: date.truncate(t: now(), unit: _window_time)) _stop = date.truncate(t: now(), unit: _window_time) a = from(bucket: _bucket) |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == \"score\") |> count() |> group() |> sort(desc: true) |> keep(columns: [\"_value\", \"doi\"]) |> rename(columns: {_value: \"count\"}) |> limit(n: _n) |> yield() \"\"\" # print(query) # print(params) tables = query_api . query ( query , params = params ) results = [] for table in tables : for record in table . records : results . append ( record [ 'doi' ]) # print(results) return results get_top_n_trending_dois ( session , duration = 'currently' , n = 5 ) get top trending dois, postgresql Source code in daos/stats.py def get_top_n_trending_dois ( session : Session , duration = \"currently\" , n = 5 ): \"\"\" get top trending dois, postgresql \"\"\" query = \"\"\" SELECT publication_doi FROM trending t WHERE duration = :duration ORDER BY score DESC LIMIT :n; \"\"\" params = { 'duration' : duration , 'n' : n } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'n' )) rows = session . execute ( s , params ) . fetchall () result = [] for r in rows : result . append ( r [ 0 ]) return result get_total_tweet_count ( doi , session , id , mode = 'publication' ) get tweet author count from postgresql Source code in daos/stats.py def get_total_tweet_count ( doi , session : Session , id , mode = \"publication\" ): \"\"\" get tweet author count from postgresql \"\"\" params = {} if mode == \"fieldOfStudy\" : query = \"\"\"SELECT SUM(count) as count FROM discussion_data_point as ddp JOIN publication_field_of_study as pfos on ddp.publication_doi = pfos.publication_doi WHERE ddp.discussion_data_point_id IN (12,50,88,141) AND pfos.field_of_study_id=:id \"\"\" params [ 'id' ] = id elif mode == \"author\" : query = \"\"\"SELECT SUM(count) as count FROM discussion_data_point as ddp JOIN publication_author as pfos on ddp.publication_doi = pfos.publication_doi WHERE ddp.discussion_data_point_id IN (12,50,88,141) AND pfos.author_id=:id \"\"\" params [ 'id' ] = id else : # default publication query = \"\"\"SELECT SUM(count) FROM discussion_data_point ddp WHERE ddp.discussion_data_point_id IN (12,50,88,141) \"\"\" if doi : query += \" AND publication_doi = :doi \" params [ 'doi' ] = doi # print(query) # print(params) s = text ( query ) if doi : s = s . bindparams ( bindparam ( 'doi' )) return session . execute ( s , params ) . fetchall () get_trending_chart_data ( query_api , session , duration = 'currently' , field = 'score' , n = 5 , dois = None ) get trending data for given dois over a period of time from influx, mainly used for charts Source code in daos/stats.py def get_trending_chart_data ( query_api , session : Session , duration = \"currently\" , field = \"score\" , n = 5 , dois = None ): \"\"\" get trending data for given dois over a period of time from influx, mainly used for charts \"\"\" fields = [ 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' ] if field not in fields : return None if field == 'sum_followers' : field = 'sum_follower' params = { '_field_name' : field , \"_start\" : trending_time_definition [ duration ][ 'duration' ], '_bucket' : trending_time_definition [ duration ][ 'trending_bucket' ], } doi_list = dois if not doi_list : doi_list = get_top_n_trending_dois ( session , duration , n ) if len ( doi_list ) > n : doi_list = doi_list [ 0 : n ] filter_obj = doi_filter_list ( doi_list , params ) query = \"\"\" a = from(bucket: _bucket) |> range(start: _start) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == _field_name) \"\"\" query += filter_obj [ 'string' ] query += \"\"\" |> keep(columns: [\"_value\", \"_time\", \"_field\", \"doi\"]) |> yield() \"\"\" tables = query_api . query ( query , params = filter_obj [ 'params' ]) titles = get_titles_for_dois ( session , doi_list ) results = [] for table in tables : doi = None data = [] for record in table . records : point = { 'time' : record [ '_time' ] . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), 'value' : record [ '_value' ]} data . append ( point ) if not doi : doi = record [ 'doi' ] results . append ({ \"doi\" : doi , \"title\" : titles [ doi ], \"data\" : data , }) return results get_tweet_author_count ( doi , session , id , mode = 'publication' ) get tweet author count from postgresql Source code in daos/stats.py def get_tweet_author_count ( doi , session : Session , id , mode = \"publication\" ): \"\"\" get tweet author count from postgresql \"\"\" params = {} if mode == \"fieldOfStudy\" : query = \"\"\"SELECT count(id) as count FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_field_of_study as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = 'name' AND pfos.field_of_study_id=:id \"\"\" params [ 'id' ] = id elif mode == \"author\" : query = \"\"\"SELECT count(id) as count FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_author as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = 'name' AND pfos.author_id=:id \"\"\" params [ 'id' ] = id else : # default publication query = \"\"\"SELECT count(id) as count FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = 'name' \"\"\" if doi : query += \" AND publication_doi = :doi \" params [ 'doi' ] = doi # print(query) # print(params) s = text ( query ) if doi : s = s . bindparams ( bindparam ( 'doi' )) return session . execute ( s , params ) . fetchall () get_tweets ( doi , session , id , mode = 'publication' ) get newest tweet from postgresql Source code in daos/stats.py def get_tweets ( doi , session : Session , id , mode = \"publication\" ): \"\"\" get newest tweet from postgresql \"\"\" params = {} query = \"\"\" SELECT p.*, p.title, p.abstract, discussion_newest_subj.* FROM discussion_newest_subj JOIN publication p on discussion_newest_subj.publication_doi = p.doi \"\"\" if mode == \"publication\" : query += \"\"\" WHERE discussion_newest_subj.type = 'twitter' \"\"\" if mode == \"fieldOfStudy\" : query += \"\"\" JOIN publication_field_of_study pfos on discussion_newest_subj.publication_doi = pfos.publication_doi WHERE discussion_newest_subj.type = 'twitter' AND pfos.field_of_study_id = :id \"\"\" params [ 'id' ] = id if mode == \"author\" : query += \"\"\" JOIN publication_author pfos on discussion_newest_subj.publication_doi = pfos.publication_doi WHERE discussion_newest_subj.type = 'twitter' AND pfos.author_id = :id \"\"\" params [ 'id' ] = id extra = \"\"\" ORDER BY created_at DESC LIMIT 1; \"\"\" if doi : query += \" AND publication_doi = :doi \" params [ 'doi' ] = doi query += extra # print(query) # print(params) s = text ( query ) if doi : s = s . bindparams ( bindparam ( 'doi' )) if id : s = s . bindparams ( bindparam ( 'id' )) tweet_data = session . execute ( s , params ) . fetchone () a = text ( \"\"\"SELECT id, name FROM publication_author as p JOIN author as a on (a.id = p.author_id) WHERE p.publication_doi=:doi\"\"\" ) params = { 'doi' : tweet_data [ 'doi' ], } a = a . bindparams ( bindparam ( 'doi' )) authors = session . execute ( a , params ) . fetchall () return { 'authors' : authors , 'data' : tweet_data } get_window_chart_data ( query_api , session , duration = 'currently' , field = 'score' , n = 5 , dois = None ) get window value data for given dois over a period of time from influx, mainly used for charts Source code in daos/stats.py def get_window_chart_data ( query_api , session : Session , duration = \"currently\" , field = \"score\" , n = 5 , dois = None ): \"\"\" get window value data for given dois over a period of time from influx, mainly used for charts \"\"\" aggregation_field = { 'bot_rating' : 'mean' , 'contains_abstract_raw' : 'mean' , 'exclamations' : 'mean' , 'followers' : 'sum' , 'length' : 'mean' , 'questions' : 'mean' , 'score' : 'sum' , 'sentiment_raw' : 'mean' , \"count\" : \"count\" } if field not in aggregation_field : return None else : aggregator = aggregation_field [ field ] if field == \"count\" : if duration == \"currently\" : field = \"score\" else : aggregator = \"sum\" params = { '_field_name' : field , '_window_time' : trending_time_definition [ duration ][ 'window_size' ], \"_duration_time\" : timedelta ( seconds =- trending_time_definition [ duration ][ 'duration' ] . total_seconds ()), '_bucket' : trending_time_definition [ duration ][ 'name' ], } doi_list = dois if not doi_list or len ( doi_list ) == 0 or doi_list is None : doi_list = get_top_n_trending_dois ( session , duration , n ) if not doi_list or len ( doi_list ) == 0 or doi_list is None : doi_list = get_top_n_dois ( query_api , duration , \"count\" , n ) if len ( doi_list ) > n : doi_list = doi_list [ 0 : n ] filter_obj = doi_filter_list ( doi_list , params ) query = \"\"\" import \"experimental\" import \"date\" _start = experimental.subDuration(d: _duration_time, from: date.truncate(t: now(), unit: _window_time)) _stop = date.truncate(t: now(), unit: _window_time) a = from(bucket: _bucket) |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == _field_name)\"\"\" query += filter_obj [ 'string' ] query += \"\"\" |> aggregateWindow(every: _window_time, fn: \"\"\" + aggregator + \"\"\", createEmpty: false) |> keep(columns: [\"_value\", \"_time\", \"_field\", \"doi\"]) |> yield() \"\"\" tables = query_api . query ( query , params = filter_obj [ 'params' ]) titles = get_titles_for_dois ( session , doi_list ) results = [] for table in tables : doi = None data = [] for record in table . records : point = { 'time' : record [ '_time' ] . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), 'value' : record [ '_value' ]} data . append ( point ) if not doi : doi = record [ 'doi' ] results . append ({ \"doi\" : doi , \"title\" : titles [ doi ], \"data\" : data , }) return results system_running_check ( query_api ) check if the system is running correctly by counting how many tweets we got in the last 5 minutes, if over 10 than ok Source code in daos/stats.py def system_running_check ( query_api ): \"\"\" check if the system is running correctly by counting how many tweets we got in the last 5 minutes, if over 10 than ok\"\"\" query = \"\"\" from(bucket: \"currently\") |> range(start: -5m) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == \"score\") |> group() |> count() |> yield(name: \"count\") \"\"\" # print(query) # print(params) tables = query_api . query ( query ) count = 0 for table in tables : for record in table . records : count = record [ '_value' ] if count > 10 : return 'ok' return 'not running'","title":"stats"},{"location":"daos/stats_ref/#daos.stats.doi_filter_list","text":"influx helper adding a doi filter list (faster than array check in influx) Source code in daos/stats.py def doi_filter_list ( doi_list , params ): \"\"\" influx helper adding a doi filter list (faster than array check in influx) \"\"\" if doi_list : filter_string = \"\"\" |> filter(fn: (r) => \"\"\" i = 0 for doi in doi_list : filter_string += 'r[\"doi\"] == _doi_nr_' + str ( i ) + ' or ' params [ '_doi_nr_' + str ( i )] = doi i += 1 filter_string = filter_string [: - 4 ] + ')' return { \"string\" : filter_string , \"params\" : params } return { \"string\" : '' , \"params\" : params }","title":"doi_filter_list()"},{"location":"daos/stats_ref/#daos.stats.fetch_with_doi_filter","text":"postresql helper to add a doi filter Source code in daos/stats.py def fetch_with_doi_filter ( session : Session , query , doi ): \"\"\" postresql helper to add a doi filter \"\"\" if doi : query += 'WHERE publication_doi=:doi' params = { 'doi' : doi , } s = text ( query ) s = s . bindparams ( bindparam ( 'doi' )) return session . execute ( s , params ) . fetchall () s = text ( query ) return session . execute ( s ) . fetchall ()","title":"fetch_with_doi_filter()"},{"location":"daos/stats_ref/#daos.stats.get_discussion_data_list","text":"get discussion types with count from postgresql Source code in daos/stats.py def get_discussion_data_list ( session : Session , doi , limit , id , mode = \"publication\" , dd_type = \"word\" ): \"\"\" get discussion types with count from postgresql \"\"\" params = { 'type' : dd_type } if mode == \"fieldOfStudy\" : query = \"\"\"SELECT SUM(ddp.count) as count, dd.value FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_field_of_study as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = :type and value != 'und' and value != 'unknown' AND pfos.field_of_study_id=:id \"\"\" params [ 'id' ] = id elif mode == \"author\" : query = \"\"\"SELECT SUM(ddp.count) as count, dd.value FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_author as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = :type and value != 'und' and value != 'unknown' AND pfos.author_id=:id \"\"\" params [ 'id' ] = id else : # default publication query = \"\"\"SELECT SUM(ddp.count) as count, dd.value FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = :type and value != 'und' and value != 'unknown' \"\"\" extra = \"\"\" GROUP BY dd.id ORDER BY count DESC \"\"\" if limit : params [ 'limit' ] = limit extra += \" LIMIT :limit \" if doi : query += 'AND publication_doi=:doi ' params [ 'doi' ] = doi query += extra s = text ( query ) # print(query) # print(params) if 'doi' in params and 'limit' in params : # print('type, doi, limit') s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'doi' ), bindparam ( 'limit' )) elif 'doi' in params : # print('doi, type') s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'doi' )) elif 'limit' in params : # print('type, limit') s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'limit' )) else : # print('type') s = s . bindparams ( bindparam ( 'type' )) return session . execute ( s , params ) . fetchall ()","title":"get_discussion_data_list()"},{"location":"daos/stats_ref/#daos.stats.get_discussion_data_list_with_percentage","text":"get discussion types with count an percentage from postgresql Source code in daos/stats.py def get_discussion_data_list_with_percentage ( session : Session , doi , limit : int = 20 , min_percentage : float = 1 , dd_type = \"lang\" ): \"\"\" get discussion types with count an percentage from postgresql \"\"\" query = \"\"\" WITH result AS ( ( SELECT \"value\", SUM(count) as c, ROUND(SUM(count) / CAST(SUM(SUM(count)) OVER () AS FLOAT) * 1000) / 10 as p FROM (SELECT \"value\", \"count\" FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = :type and value != 'und' and value != 'unknown' \"\"\" extra1 = \"\"\") temp GROUP BY \"value\" ORDER BY c DESC LIMIT :limit ) UNION ( SELECT 'total' as \"value\", SUM(count) as c, 100 as p FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = :type and value != 'und' and value != 'unknown' \"\"\" extra2 = \"\"\" ) ) SELECT \"value\", c as count, p FROM result WHERE result.p >= :mp ORDER BY count DESC; \"\"\" params = { 'type' : dd_type , 'limit' : limit , 'mp' : min_percentage } if doi : query += ' AND publication_doi=:doi ' params [ 'doi' ] = doi query += extra1 if doi : query += ' AND publication_doi=:doi ' query += extra2 s = text ( query ) # print(query) # print(params) if 'doi' in params : s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'limit' ), bindparam ( 'mp' ), bindparam ( 'doi' )) else : s = s . bindparams ( bindparam ( 'type' ), bindparam ( 'limit' ), bindparam ( 'mp' )) return session . execute ( s , params ) . fetchall ()","title":"get_discussion_data_list_with_percentage()"},{"location":"daos/stats_ref/#daos.stats.get_dois_for_author","text":"get dois for a given author from postgresql Source code in daos/stats.py def get_dois_for_author ( id , session : Session , duration = \"currently\" ): \"\"\" get dois for a given author from postgresql \"\"\" query = \"\"\" SELECT t.publication_doi FROM trending t JOIN publication_author pa on t.publication_doi = pa.publication_doi WHERE duration = :duration AND pa.author_id = :author_id; \"\"\" params = { 'duration' : duration , 'author_id' : id } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'author_id' )) rows = session . execute ( s , params ) . fetchall () result = [] for r in rows : result . append ( r [ 0 ]) # print(result) return result","title":"get_dois_for_author()"},{"location":"daos/stats_ref/#daos.stats.get_dois_for_field_of_study","text":"get dois for a given field of study from postgresql Source code in daos/stats.py def get_dois_for_field_of_study ( id , session : Session , duration = \"currently\" ): \"\"\" get dois for a given field of study from postgresql \"\"\" query = \"\"\" SELECT t.publication_doi FROM trending t JOIN publication_field_of_study pfos on t.publication_doi = pfos.publication_doi WHERE duration = :duration AND field_of_study_id = :fos_id; \"\"\" params = { 'duration' : duration , 'fos_id' : id } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'fos_id' )) rows = session . execute ( s , params ) . fetchall () result = [] for r in rows : result . append ( r [ 0 ]) # print(result) return result","title":"get_dois_for_field_of_study()"},{"location":"daos/stats_ref/#daos.stats.get_number_influx","text":"get influx number for specific dois calculating, returns string query Source code in daos/stats.py def get_number_influx ( filter_obj , duration = \"currently\" , field = \"score\" ): \"\"\" get influx number for specific dois calculating, returns string query\"\"\" aggregation_field = { 'bot_rating' : 'mean' , 'contains_abstract_raw' : 'mean' , 'exclamations' : 'mean' , 'followers' : 'sum' , 'length' : 'mean' , 'questions' : 'mean' , 'score' : 'sum' , 'sentiment_raw' : 'mean' , \"pub_count\" : \"count\" , \"count\" : \"count\" } if field not in aggregation_field : # print('not in field') # return PlainTextResponse(content='field ' + field + ' not found') return None else : aggregator = aggregation_field [ field ] field_selector = field if field == \"count\" : field = \"temp_count\" # avoid trouble with renaming a function (count()) if duration == \"currently\" : field_selector = \"score\" else : aggregator = \"sum\" if field == \"pub_count\" : field_selector = 'score' query = field + ''' = from(bucket: _bucket) |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == \"''' + field_selector + '\")' if filter_obj : query += filter_obj [ 'string' ] query += \"\"\" |> group() \"\"\" if field == \"pub_count\" : query += '|> distinct(column: \"doi\")' if field == \"temp_count\" : field = \"count\" query += ''' |> ''' + aggregator + '''() |> keep(columns: [\"_value\", \"_time\", \"doi\"]) |> yield(name: \"''' + field + '''\") ''' return query","title":"get_number_influx()"},{"location":"daos/stats_ref/#daos.stats.get_numbers_influx","text":"get numbers from influx, switch between getting (total) and calculating (for dois) Source code in daos/stats.py def get_numbers_influx ( query_api , dois , duration = \"currently\" , fields = None ): \"\"\" get numbers from influx, switch between getting (total) and calculating (for dois) \"\"\" if fields is None : fields = [ \"score\" ] query = \"\"\" _start = _duration_time _stop = now() \"\"\" params = { '_duration_time' : trending_time_definition [ duration ][ 'duration' ], '_bucket' : trending_time_definition [ duration ][ 'name' ], } if dois : filter_obj = doi_filter_list ( dois , params ) # print('get numbers') for field in fields : query += get_number_influx ( filter_obj , duration , field ) tables = query_api . query ( query , params = filter_obj [ 'params' ]) else : # print('get task numbers') for field in fields : query += get_task_number_influx ( duration , field ) # print(query) tables = query_api . query ( query , params = params ) result = {} for table in tables : for record in table . records : result [ record [ 'result' ]] = record [ '_value' ] return result","title":"get_numbers_influx()"},{"location":"daos/stats_ref/#daos.stats.get_profile_information_avg","text":"get profile information avg, min, max from postgresql Source code in daos/stats.py def get_profile_information_avg ( session : Session , duration = \"currently\" ): \"\"\" get profile information avg, min, max from postgresql \"\"\" query = \"\"\" SELECT 'mean_score' as type, MIN(mean_score), MAX(mean_score), AVG(mean_score) FROM trending WHERE duration = :duration UNION SELECT 'mean_bot_rating' as type, MIN(mean_bot_rating), MAX(mean_bot_rating), AVG(mean_bot_rating) FROM trending WHERE duration = :duration UNION SELECT 'mean_sentiment' as type, MIN(mean_sentiment), MAX(mean_sentiment), AVG(mean_sentiment) FROM trending WHERE duration = :duration UNION SELECT 'sum_followers' as type, MIN(sum_followers), MAX(sum_followers), AVG(sum_followers) FROM trending WHERE duration = :duration UNION SELECT 'abstract_difference' as type, MIN(abstract_difference), MAX(abstract_difference), AVG(abstract_difference) FROM trending WHERE duration = :duration UNION SELECT 'mean_questions' as type, MIN(mean_questions), MAX(mean_questions), AVG(mean_questions) FROM trending WHERE duration = :duration UNION SELECT 'mean_exclamations' as type, MIN(mean_exclamations), MAX(mean_exclamations), AVG(mean_exclamations) FROM trending WHERE duration = :duration UNION SELECT 'mean_length' as type, MIN(mean_length), MAX(mean_length), AVG(mean_length) FROM trending WHERE duration = :duration; \"\"\" params = { 'duration' : duration , } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' )) rows = session . execute ( s , params ) . fetchall () result = { 'min' : {}, 'max' : {}, 'avg' : {}} for r in rows : result [ 'min' ][ r [ 0 ]] = r [ 1 ] result [ 'max' ][ r [ 0 ]] = r [ 2 ] result [ 'avg' ][ r [ 0 ]] = r [ 3 ] return result","title":"get_profile_information_avg()"},{"location":"daos/stats_ref/#daos.stats.get_profile_information_for_doi","text":"get profile information for a doi, fieldOfStudy or Author Source code in daos/stats.py def get_profile_information_for_doi ( session : Session , doi , id , mode = \"publication\" , duration = \"currently\" ): \"\"\" get profile information for a doi, fieldOfStudy or Author\"\"\" query = \"\"\" SELECT AVG(mean_score) mean_score, AVG(abstract_difference) abstract_difference, AVG(mean_sentiment) mean_sentiment, \"\"\" if mode == \"publication\" : query += \"SUM(sum_followers) sum_followers,\" else : query += \"AVG(sum_followers) sum_followers,\" query += \"\"\" AVG(mean_length) mean_length, AVG(mean_questions) mean_questions, AVG(mean_exclamations) mean_exclamations, AVG(mean_bot_rating) mean_bot_rating FROM ( SELECT DISTINCT doi, mean_score, abstract_difference, mean_sentiment, sum_followers, mean_length, mean_questions, mean_exclamations, mean_bot_rating FROM trending t LEFT JOIN publication p on p.doi = t.publication_doi LEFT JOIN publication_field_of_study pfos on p.doi = pfos.publication_doi LEFT JOIN publication_author pa on p.doi = pa.publication_doi WHERE duration = :duration \"\"\" params = { 'duration' : duration } if mode == \"publication\" : query += \"AND doi = :doi\" params [ 'doi' ] = doi if mode == \"author\" : query += \"AND author_id = :id\" params [ 'id' ] = id if mode == \"fieldOfStudy\" : query += \"AND field_of_study_id = :id\" params [ 'id' ] = id query += \" ) t\" s = text ( query ) # print(query) # print(params) if 'id' in params : s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'id' )) elif 'doi' in params : s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'doi' )) return session . execute ( s , params ) . fetchone () . _asdict ()","title":"get_profile_information_for_doi()"},{"location":"daos/stats_ref/#daos.stats.get_task_number_influx","text":"get number from task (own bucket for total numbers, returns string query) Source code in daos/stats.py def get_task_number_influx ( duration = \"currently\" , field = \"score\" ): \"\"\" get number from task (own bucket for total numbers, returns string query) \"\"\" aggregation_field = { 'bot_rating' : 'mean' , 'contains_abstract_raw' : 'mean' , 'exclamations' : 'mean' , 'followers' : 'sum' , 'length' : 'mean' , 'questions' : 'mean' , 'score' : 'sum' , 'sentiment_raw' : 'mean' , \"pub_count\" : \"count\" , \"count\" : \"count\" } if field not in aggregation_field : # print('not in field') # return PlainTextResponse(content='field ' + field + ' not found') return None else : query = field + ''' = from(bucket: \"numbers\") |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"''' + duration + '''\") |> filter(fn: (r) => r[\"_field\"] == \"''' + field + '''\") |> last() |> keep(columns: [\"_value\", \"_time\", \"doi\"]) |> yield(name: \"''' + field + '''\") ''' return query","title":"get_task_number_influx()"},{"location":"daos/stats_ref/#daos.stats.get_top_n_dois","text":"get top n dois by count, expensive query, influx db Source code in daos/stats.py def get_top_n_dois ( query_api , duration = \"currently\" , field = \"count\" , n = 5 ): \"\"\" get top n dois by count, expensive query, influx db \"\"\" if field == \"count\" : params = { '_window_time' : trending_time_definition [ duration ][ 'window_size' ], \"_duration_time\" : timedelta ( seconds =- trending_time_definition [ duration ][ 'duration' ] . total_seconds ()), '_bucket' : trending_time_definition [ duration ][ 'name' ], '_n' : n , } query = \"\"\" import \"experimental\" import \"date\" _start = experimental.subDuration(d: _duration_time, from: date.truncate(t: now(), unit: _window_time)) _stop = date.truncate(t: now(), unit: _window_time) a = from(bucket: _bucket) |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == \"score\") |> count() |> group() |> sort(desc: true) |> keep(columns: [\"_value\", \"doi\"]) |> rename(columns: {_value: \"count\"}) |> limit(n: _n) |> yield() \"\"\" # print(query) # print(params) tables = query_api . query ( query , params = params ) results = [] for table in tables : for record in table . records : results . append ( record [ 'doi' ]) # print(results) return results","title":"get_top_n_dois()"},{"location":"daos/stats_ref/#daos.stats.get_top_n_trending_dois","text":"get top trending dois, postgresql Source code in daos/stats.py def get_top_n_trending_dois ( session : Session , duration = \"currently\" , n = 5 ): \"\"\" get top trending dois, postgresql \"\"\" query = \"\"\" SELECT publication_doi FROM trending t WHERE duration = :duration ORDER BY score DESC LIMIT :n; \"\"\" params = { 'duration' : duration , 'n' : n } s = text ( query ) s = s . bindparams ( bindparam ( 'duration' ), bindparam ( 'n' )) rows = session . execute ( s , params ) . fetchall () result = [] for r in rows : result . append ( r [ 0 ]) return result","title":"get_top_n_trending_dois()"},{"location":"daos/stats_ref/#daos.stats.get_total_tweet_count","text":"get tweet author count from postgresql Source code in daos/stats.py def get_total_tweet_count ( doi , session : Session , id , mode = \"publication\" ): \"\"\" get tweet author count from postgresql \"\"\" params = {} if mode == \"fieldOfStudy\" : query = \"\"\"SELECT SUM(count) as count FROM discussion_data_point as ddp JOIN publication_field_of_study as pfos on ddp.publication_doi = pfos.publication_doi WHERE ddp.discussion_data_point_id IN (12,50,88,141) AND pfos.field_of_study_id=:id \"\"\" params [ 'id' ] = id elif mode == \"author\" : query = \"\"\"SELECT SUM(count) as count FROM discussion_data_point as ddp JOIN publication_author as pfos on ddp.publication_doi = pfos.publication_doi WHERE ddp.discussion_data_point_id IN (12,50,88,141) AND pfos.author_id=:id \"\"\" params [ 'id' ] = id else : # default publication query = \"\"\"SELECT SUM(count) FROM discussion_data_point ddp WHERE ddp.discussion_data_point_id IN (12,50,88,141) \"\"\" if doi : query += \" AND publication_doi = :doi \" params [ 'doi' ] = doi # print(query) # print(params) s = text ( query ) if doi : s = s . bindparams ( bindparam ( 'doi' )) return session . execute ( s , params ) . fetchall ()","title":"get_total_tweet_count()"},{"location":"daos/stats_ref/#daos.stats.get_trending_chart_data","text":"get trending data for given dois over a period of time from influx, mainly used for charts Source code in daos/stats.py def get_trending_chart_data ( query_api , session : Session , duration = \"currently\" , field = \"score\" , n = 5 , dois = None ): \"\"\" get trending data for given dois over a period of time from influx, mainly used for charts \"\"\" fields = [ 'score' , 'count' , 'mean_sentiment' , 'sum_followers' , 'abstract_difference' , 'mean_age' , 'mean_length' , 'mean_questions' , 'mean_exclamations' , 'mean_bot_rating' , 'projected_change' , 'trending' , 'ema' , 'kama' , 'ker' , 'mean_score' , 'stddev' ] if field not in fields : return None if field == 'sum_followers' : field = 'sum_follower' params = { '_field_name' : field , \"_start\" : trending_time_definition [ duration ][ 'duration' ], '_bucket' : trending_time_definition [ duration ][ 'trending_bucket' ], } doi_list = dois if not doi_list : doi_list = get_top_n_trending_dois ( session , duration , n ) if len ( doi_list ) > n : doi_list = doi_list [ 0 : n ] filter_obj = doi_filter_list ( doi_list , params ) query = \"\"\" a = from(bucket: _bucket) |> range(start: _start) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == _field_name) \"\"\" query += filter_obj [ 'string' ] query += \"\"\" |> keep(columns: [\"_value\", \"_time\", \"_field\", \"doi\"]) |> yield() \"\"\" tables = query_api . query ( query , params = filter_obj [ 'params' ]) titles = get_titles_for_dois ( session , doi_list ) results = [] for table in tables : doi = None data = [] for record in table . records : point = { 'time' : record [ '_time' ] . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), 'value' : record [ '_value' ]} data . append ( point ) if not doi : doi = record [ 'doi' ] results . append ({ \"doi\" : doi , \"title\" : titles [ doi ], \"data\" : data , }) return results","title":"get_trending_chart_data()"},{"location":"daos/stats_ref/#daos.stats.get_tweet_author_count","text":"get tweet author count from postgresql Source code in daos/stats.py def get_tweet_author_count ( doi , session : Session , id , mode = \"publication\" ): \"\"\" get tweet author count from postgresql \"\"\" params = {} if mode == \"fieldOfStudy\" : query = \"\"\"SELECT count(id) as count FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_field_of_study as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = 'name' AND pfos.field_of_study_id=:id \"\"\" params [ 'id' ] = id elif mode == \"author\" : query = \"\"\"SELECT count(id) as count FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) JOIN publication_author as pfos on ddp.publication_doi = pfos.publication_doi WHERE type = 'name' AND pfos.author_id=:id \"\"\" params [ 'id' ] = id else : # default publication query = \"\"\"SELECT count(id) as count FROM discussion_data_point as ddp JOIN discussion_data as dd ON (ddp.discussion_data_point_id = dd.id) WHERE type = 'name' \"\"\" if doi : query += \" AND publication_doi = :doi \" params [ 'doi' ] = doi # print(query) # print(params) s = text ( query ) if doi : s = s . bindparams ( bindparam ( 'doi' )) return session . execute ( s , params ) . fetchall ()","title":"get_tweet_author_count()"},{"location":"daos/stats_ref/#daos.stats.get_tweets","text":"get newest tweet from postgresql Source code in daos/stats.py def get_tweets ( doi , session : Session , id , mode = \"publication\" ): \"\"\" get newest tweet from postgresql \"\"\" params = {} query = \"\"\" SELECT p.*, p.title, p.abstract, discussion_newest_subj.* FROM discussion_newest_subj JOIN publication p on discussion_newest_subj.publication_doi = p.doi \"\"\" if mode == \"publication\" : query += \"\"\" WHERE discussion_newest_subj.type = 'twitter' \"\"\" if mode == \"fieldOfStudy\" : query += \"\"\" JOIN publication_field_of_study pfos on discussion_newest_subj.publication_doi = pfos.publication_doi WHERE discussion_newest_subj.type = 'twitter' AND pfos.field_of_study_id = :id \"\"\" params [ 'id' ] = id if mode == \"author\" : query += \"\"\" JOIN publication_author pfos on discussion_newest_subj.publication_doi = pfos.publication_doi WHERE discussion_newest_subj.type = 'twitter' AND pfos.author_id = :id \"\"\" params [ 'id' ] = id extra = \"\"\" ORDER BY created_at DESC LIMIT 1; \"\"\" if doi : query += \" AND publication_doi = :doi \" params [ 'doi' ] = doi query += extra # print(query) # print(params) s = text ( query ) if doi : s = s . bindparams ( bindparam ( 'doi' )) if id : s = s . bindparams ( bindparam ( 'id' )) tweet_data = session . execute ( s , params ) . fetchone () a = text ( \"\"\"SELECT id, name FROM publication_author as p JOIN author as a on (a.id = p.author_id) WHERE p.publication_doi=:doi\"\"\" ) params = { 'doi' : tweet_data [ 'doi' ], } a = a . bindparams ( bindparam ( 'doi' )) authors = session . execute ( a , params ) . fetchall () return { 'authors' : authors , 'data' : tweet_data }","title":"get_tweets()"},{"location":"daos/stats_ref/#daos.stats.get_window_chart_data","text":"get window value data for given dois over a period of time from influx, mainly used for charts Source code in daos/stats.py def get_window_chart_data ( query_api , session : Session , duration = \"currently\" , field = \"score\" , n = 5 , dois = None ): \"\"\" get window value data for given dois over a period of time from influx, mainly used for charts \"\"\" aggregation_field = { 'bot_rating' : 'mean' , 'contains_abstract_raw' : 'mean' , 'exclamations' : 'mean' , 'followers' : 'sum' , 'length' : 'mean' , 'questions' : 'mean' , 'score' : 'sum' , 'sentiment_raw' : 'mean' , \"count\" : \"count\" } if field not in aggregation_field : return None else : aggregator = aggregation_field [ field ] if field == \"count\" : if duration == \"currently\" : field = \"score\" else : aggregator = \"sum\" params = { '_field_name' : field , '_window_time' : trending_time_definition [ duration ][ 'window_size' ], \"_duration_time\" : timedelta ( seconds =- trending_time_definition [ duration ][ 'duration' ] . total_seconds ()), '_bucket' : trending_time_definition [ duration ][ 'name' ], } doi_list = dois if not doi_list or len ( doi_list ) == 0 or doi_list is None : doi_list = get_top_n_trending_dois ( session , duration , n ) if not doi_list or len ( doi_list ) == 0 or doi_list is None : doi_list = get_top_n_dois ( query_api , duration , \"count\" , n ) if len ( doi_list ) > n : doi_list = doi_list [ 0 : n ] filter_obj = doi_filter_list ( doi_list , params ) query = \"\"\" import \"experimental\" import \"date\" _start = experimental.subDuration(d: _duration_time, from: date.truncate(t: now(), unit: _window_time)) _stop = date.truncate(t: now(), unit: _window_time) a = from(bucket: _bucket) |> range(start: _start, stop: _stop) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == _field_name)\"\"\" query += filter_obj [ 'string' ] query += \"\"\" |> aggregateWindow(every: _window_time, fn: \"\"\" + aggregator + \"\"\", createEmpty: false) |> keep(columns: [\"_value\", \"_time\", \"_field\", \"doi\"]) |> yield() \"\"\" tables = query_api . query ( query , params = filter_obj [ 'params' ]) titles = get_titles_for_dois ( session , doi_list ) results = [] for table in tables : doi = None data = [] for record in table . records : point = { 'time' : record [ '_time' ] . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), 'value' : record [ '_value' ]} data . append ( point ) if not doi : doi = record [ 'doi' ] results . append ({ \"doi\" : doi , \"title\" : titles [ doi ], \"data\" : data , }) return results","title":"get_window_chart_data()"},{"location":"daos/stats_ref/#daos.stats.system_running_check","text":"check if the system is running correctly by counting how many tweets we got in the last 5 minutes, if over 10 than ok Source code in daos/stats.py def system_running_check ( query_api ): \"\"\" check if the system is running correctly by counting how many tweets we got in the last 5 minutes, if over 10 than ok\"\"\" query = \"\"\" from(bucket: \"currently\") |> range(start: -5m) |> filter(fn: (r) => r[\"_measurement\"] == \"trending\") |> filter(fn: (r) => r[\"_field\"] == \"score\") |> group() |> count() |> yield(name: \"count\") \"\"\" # print(query) # print(params) tables = query_api . query ( query ) count = 0 for table in tables : for record in table . records : count = record [ '_value' ] if count > 10 : return 'ok' return 'not running'","title":"system_running_check()"},{"location":"models/schema/","text":"PublicationType ( str , Enum ) An enumeration.","title":"schema"},{"location":"models/schema/#models.schema.PublicationType","text":"An enumeration.","title":"PublicationType"},{"location":"routers/author_ref/","text":"get_author ( id , session = Depends ( get_session )) Get author data for a given id. it will also return the publication data of all publications in a given author. id : id of the author to get Source code in routers/author.py @router . get ( \"/get\" , summary = \"Get Author.\" , response_model = AmbaResponse ) def get_author ( id : int , session : Session = Depends ( get_session )): \"\"\" Get author data for a given id. it will also return the publication data of all publications in a given author. - **id**: id of the author to get \"\"\" start = time . time () item = retrieve_author ( session , id ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_session () get/create a session Source code in routers/author.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close () get_trending_authors_router ( offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , search = '' , duration = 'currently' , session = Depends ( get_session )) Return trending authors and their trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/author.py @router . get ( \"/trending\" , summary = \"Get trending Authors.\" , response_model = AmbaResponse ) def get_trending_authors_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session )): \"\"\" Return trending authors and their trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_authors ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"author"},{"location":"routers/author_ref/#routers.author.get_author","text":"Get author data for a given id. it will also return the publication data of all publications in a given author. id : id of the author to get Source code in routers/author.py @router . get ( \"/get\" , summary = \"Get Author.\" , response_model = AmbaResponse ) def get_author ( id : int , session : Session = Depends ( get_session )): \"\"\" Get author data for a given id. it will also return the publication data of all publications in a given author. - **id**: id of the author to get \"\"\" start = time . time () item = retrieve_author ( session , id ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_author()"},{"location":"routers/author_ref/#routers.author.get_session","text":"get/create a session Source code in routers/author.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close ()","title":"get_session()"},{"location":"routers/author_ref/#routers.author.get_trending_authors_router","text":"Return trending authors and their trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/author.py @router . get ( \"/trending\" , summary = \"Get trending Authors.\" , response_model = AmbaResponse ) def get_trending_authors_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session )): \"\"\" Return trending authors and their trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_authors ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_trending_authors_router()"},{"location":"routers/field_of_study_ref/","text":"get_field_of_study_data ( id , session = Depends ( get_session ), with_pubs = False ) Get field of study data for a given id. it will also return the publication data of all publications in a given field of study. id : id of the field of study to get Source code in routers/field_of_study.py @router . get ( \"/get\" , summary = \"Get Field of Study.\" , response_model = AmbaResponse ) def get_field_of_study_data ( id : int , session : Session = Depends ( get_session ), with_pubs : bool = False ): \"\"\" Get field of study data for a given id. it will also return the publication data of all publications in a given field of study. - **id**: id of the field of study to get \"\"\" start = time . time () item = retrieve_field_of_study ( session , id , with_pubs ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_session () get/create a session Source code in routers/field_of_study.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close () get_trending_fields_of_study_router ( offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , search = '' , duration = 'currently' , session = Depends ( get_session )) Return trending fields of study and their trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/field_of_study.py @router . get ( \"/trending\" , summary = \"Get trending Fields of Study.\" , response_model = AmbaResponse ) def get_trending_fields_of_study_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session )): \"\"\" Return trending fields of study and their trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_fields_of_study ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"field_of_study"},{"location":"routers/field_of_study_ref/#routers.field_of_study.get_field_of_study_data","text":"Get field of study data for a given id. it will also return the publication data of all publications in a given field of study. id : id of the field of study to get Source code in routers/field_of_study.py @router . get ( \"/get\" , summary = \"Get Field of Study.\" , response_model = AmbaResponse ) def get_field_of_study_data ( id : int , session : Session = Depends ( get_session ), with_pubs : bool = False ): \"\"\" Get field of study data for a given id. it will also return the publication data of all publications in a given field of study. - **id**: id of the field of study to get \"\"\" start = time . time () item = retrieve_field_of_study ( session , id , with_pubs ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_field_of_study_data()"},{"location":"routers/field_of_study_ref/#routers.field_of_study.get_session","text":"get/create a session Source code in routers/field_of_study.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close ()","title":"get_session()"},{"location":"routers/field_of_study_ref/#routers.field_of_study.get_trending_fields_of_study_router","text":"Return trending fields of study and their trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/field_of_study.py @router . get ( \"/trending\" , summary = \"Get trending Fields of Study.\" , response_model = AmbaResponse ) def get_trending_fields_of_study_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session )): \"\"\" Return trending fields of study and their trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_fields_of_study ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_trending_fields_of_study_router()"},{"location":"routers/publication_ref/","text":"get_publication_data ( doi , duration = 'currently' , session = Depends ( get_session )) get publication data for a given doi doi : doi of the publication to get duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/get\" , summary = \"Get publication.\" , response_model = AmbaResponse ) def get_publication_data ( doi : str , duration : str = \"currently\" , session : Session = Depends ( get_session )): \"\"\" get publication data for a given doi - **doi**: doi of the publication to get - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" logging . warning ( 'retrieve publication ' + doi ) logging . warning ( 'retrieve publication ' + unquote ( doi )) start = time . time () publication = retrieve_publication ( session , doi , duration ) logging . warning ( publication ) json_compatible_item_data = jsonable_encoder ( publication ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_session () get/create a session Source code in routers/publication.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close () get_trending__covid_publications_router ( offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , search = '' , duration = 'currently' , session = Depends ( get_session )) Return covid related publication trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending/covid\" , summary = \"Get trending covid publications.\" , response_model = AmbaResponse ) def get_trending__covid_publications_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return covid related publication trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_covid_publications ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_trending_publications_for_author_router ( id , offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , search = '' , duration = 'currently' , session = Depends ( get_session )) Return publications and their trending data for a given duration and author. id : authorId offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending/author\" , summary = \"Get trending publications for a given author.\" , response_model = AmbaResponse ) def get_trending_publications_for_author_router ( id : int , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return publications and their trending data for a given duration and author. - **id**: authorId - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_publications_for_author ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search , author_id = id ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_trending_publications_for_field_of_study_router ( id , offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , search = '' , duration = 'currently' , session = Depends ( get_session )) Return publications and their trending data for a given duration and field of study. id : fieldOfStudyId offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending/fieldOfScience\" , summary = \"Get trending publications for a given field of study.\" , response_model = AmbaResponse ) def get_trending_publications_for_field_of_study_router ( id : int , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return publications and their trending data for a given duration and field of study. - **id**: fieldOfStudyId - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_publications_for_field_of_study ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search , fos_id = id ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_trending_publications_router ( offset = 0 , limit = 10 , sort = 'score' , order = 'desc' , search = '' , duration = 'currently' , session = Depends ( get_session )) Return publication trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending\" , summary = \"Get trending publications.\" , response_model = AmbaResponse ) def get_trending_publications_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return publication trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_publications ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"publication"},{"location":"routers/publication_ref/#routers.publication.get_publication_data","text":"get publication data for a given doi doi : doi of the publication to get duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/get\" , summary = \"Get publication.\" , response_model = AmbaResponse ) def get_publication_data ( doi : str , duration : str = \"currently\" , session : Session = Depends ( get_session )): \"\"\" get publication data for a given doi - **doi**: doi of the publication to get - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" logging . warning ( 'retrieve publication ' + doi ) logging . warning ( 'retrieve publication ' + unquote ( doi )) start = time . time () publication = retrieve_publication ( session , doi , duration ) logging . warning ( publication ) json_compatible_item_data = jsonable_encoder ( publication ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_publication_data()"},{"location":"routers/publication_ref/#routers.publication.get_session","text":"get/create a session Source code in routers/publication.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close ()","title":"get_session()"},{"location":"routers/publication_ref/#routers.publication.get_trending__covid_publications_router","text":"Return covid related publication trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending/covid\" , summary = \"Get trending covid publications.\" , response_model = AmbaResponse ) def get_trending__covid_publications_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return covid related publication trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_covid_publications ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_trending__covid_publications_router()"},{"location":"routers/publication_ref/#routers.publication.get_trending_publications_for_author_router","text":"Return publications and their trending data for a given duration and author. id : authorId offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending/author\" , summary = \"Get trending publications for a given author.\" , response_model = AmbaResponse ) def get_trending_publications_for_author_router ( id : int , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return publications and their trending data for a given duration and author. - **id**: authorId - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_publications_for_author ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search , author_id = id ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_trending_publications_for_author_router()"},{"location":"routers/publication_ref/#routers.publication.get_trending_publications_for_field_of_study_router","text":"Return publications and their trending data for a given duration and field of study. id : fieldOfStudyId offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending/fieldOfScience\" , summary = \"Get trending publications for a given field of study.\" , response_model = AmbaResponse ) def get_trending_publications_for_field_of_study_router ( id : int , offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return publications and their trending data for a given duration and field of study. - **id**: fieldOfStudyId - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_publications_for_field_of_study ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search , fos_id = id ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_trending_publications_for_field_of_study_router()"},{"location":"routers/publication_ref/#routers.publication.get_trending_publications_router","text":"Return publication trending data for a given duration. offset : offset limit : limit the result sort : field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' order : 'asc' or 'desc' search : search keyword (title only) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' Source code in routers/publication.py @router . get ( \"/trending\" , summary = \"Get trending publications.\" , response_model = AmbaResponse ) def get_trending_publications_router ( offset : int = 0 , limit : int = 10 , sort : str = 'score' , order : str = 'desc' , search : str = '' , duration : str = \"currently\" , session : Session = Depends ( get_session ) ): \"\"\" Return publication trending data for a given duration. - **offset**: offset - **limit**: limit the result - **sort**: field to use for sort, available: 'score', 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'tweet_author_diversity', 'lan_diversity', 'location_diversity', 'mean_age', 'mean_length', 'avg_questions', 'avg_exclamations', 'projected_change' - **order**: 'asc' or 'desc' - **search**: search keyword (title only) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' \"\"\" start = time . time () item = get_trending_publications ( session = session , offset = offset , limit = limit , sort = sort , order = order , duration = duration , search = search ) json_compatible_item_data = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_trending_publications_router()"},{"location":"routers/stats_ref/","text":"get_count_total_tweets ( doi = Query ( None ), mode = 'publication' , id = None , session = Depends ( get_session )) Get total tweet count. doi : (optional) only use the given doi mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/countTweets\" , summary = \"Get total tweet count.\" , response_model = AmbaResponse ) def get_count_total_tweets ( doi : Optional [ str ] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Get total tweet count. - **doi**: (optional) only use the given doi - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () json_compatible_item_data = get_total_tweet_count ( doi = doi , session = session , id = id , mode = mode ) return { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data } get_count_tweet_author ( doi = Query ( None ), mode = 'publication' , id = None , session = Depends ( get_session )) Get total tweet author count. doi : (optional) only use the given doi mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/countTweetAuthors\" , summary = \"Get total tweet author count.\" , response_model = AmbaResponse ) def get_count_tweet_author ( doi : Optional [ str ] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Get total tweet author count. - **doi**: (optional) only use the given doi - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () json_compatible_item_data = get_tweet_author_count ( doi = doi , session = session , id = id , mode = mode ) return { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data } get_numbers ( fields = Query ( None ), dois = Query ( None ), duration = 'currently' , mode = 'publication' , id = None , session = Depends ( get_session )) Query statistical numbers for publications. fields : list of strings with one of the following values, 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score', 'sentiment_raw', \"count\" (default) dois : (optional) only use the given dois duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/numbers\" , summary = \"Get statistical numbers.\" , response_model = AmbaResponse ) def get_numbers ( fields : Optional [ List [ str ]] = Query ( None ), dois : Optional [ List [ str ]] = Query ( None ), duration : str = \"currently\" , mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Query statistical numbers for publications. - **fields**: list of strings with one of the following values, 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score', 'sentiment_raw', \"count\" (default) - **dois**: (optional) only use the given dois - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if mode == \"fieldOfStudy\" and id : dois = get_dois_for_field_of_study ( id , session , duration ) if mode == \"author\" and id : dois = get_dois_for_author ( id , session , duration ) if not fields : fields = [ 'count' ] json_compatible_item_data = get_numbers_influx ( query_api = query_api , dois = dois , duration = duration , fields = fields ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_profile_information ( doi = Query ( None ), duration = 'currently' , mode = 'publication' , id = None , session = Depends ( get_session )) Return profile information meaning it will not only return the value of the doi, author or field of study but the avg, min and max to compare against. dois : (optional) only use the given dois duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/profile\" , summary = \"Get top profile information.\" , response_model = AmbaResponse ) def get_profile_information ( doi : Optional [ str ] = Query ( None ), duration : Optional [ str ] = \"currently\" , mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Return profile information meaning it will not only return the value of the doi, author or field of study but the avg, min and max to compare against. - **dois**: (optional) only use the given dois - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if ( mode == \"publication\" and not doi ) or ( mode == \"fieldOfStudy\" and not id ) or ( mode == \"author\" and not id ): raise HTTPException ( status_code = 404 , detail = \"Missing data.\" ) doi_info = { 'publication' : get_profile_information_for_doi ( session , doi , id , mode , duration ) } if mode == \"publication\" and doi and doi_info : doi_info [ 'publication' ][ 'doi' ] = doi if mode == \"fieldOfStudy\" and id and doi_info : doi_info [ 'publication' ][ 'doi' ] = retrieve_field_of_study ( session , id )[ 'fields_of_study' ] if mode == \"author\" and id and doi_info : doi_info [ 'publication' ][ 'doi' ] = retrieve_author ( session , id )[ 'author' ] avg_info = get_profile_information_avg ( session , duration ) if doi_info and avg_info : json_compatible_item_data = jsonable_encoder ({ ** doi_info , ** avg_info }) else : json_compatible_item_data = {} return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_session () get/create a session Source code in routers/stats.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close () get_top_percentage_values ( fields = Query ( None ), doi = None , limit = 10 , min_percentage = 1 , session = Depends ( get_session )) Query accumulated top data numbers for publications with a percentage as well as a min percentage to filter out rare items. This query does not have a duration and will always return data collected over all time. fields : list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) doi : (optional) only use the given doi limit : (optional, 10) limits the result min_percentage : (optional, 1) limits the results to only items that have a higher or equal percentage Source code in routers/stats.py @router . get ( \"/top/percentages\" , summary = \"Get top numbers with percentage.\" , response_model = AmbaResponse ) def get_top_percentage_values ( fields : Optional [ List [ str ]] = Query ( None ), doi : Optional [ str ] = None , limit : int = 10 , min_percentage : float = 1 , session : Session = Depends ( get_session )): \"\"\" Query accumulated top data numbers for publications with a percentage as well as a min percentage to filter out rare items. This query does not have a duration and will always return data collected over all time. - **fields**: list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) - **doi**: (optional) only use the given doi - **limit**: (optional, 10) limits the result - **min_percentage**: (optional, 1) limits the results to only items that have a higher or equal percentage \"\"\" start = time . time () if not fields : fields = [ 'lang' ] json_compatible_item_data = {} for field in fields : item = get_discussion_data_list_with_percentage ( session = session , doi = doi , limit = limit , min_percentage = min_percentage , dd_type = field ) json_compatible_item_data [ field ] = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_top_values ( fields = Query ( None ), doi = None , limit = 10 , mode = 'publication' , id = None , session = Depends ( get_session )) Query accumulated top data numbers for publications. This query does not have a duration and will always return data collected over all time. fields : list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) doi : (optional) only use the given doi limit : (optional, 10) limits the result mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/top\" , summary = \"Get top numbers.\" , response_model = AmbaResponse ) def get_top_values ( fields : Optional [ List [ str ]] = Query ( None ), doi : Optional [ str ] = None , limit : int = 10 , mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Query accumulated top data numbers for publications. This query does not have a duration and will always return data collected over all time. - **fields**: list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) - **doi**: (optional) only use the given doi - **limit**: (optional, 10) limits the result - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if not fields : fields = [ 'word' ] json_compatible_item_data = {} for field in fields : item = get_discussion_data_list ( session = session , doi = doi , limit = limit , dd_type = field , id = id , mode = mode ) json_compatible_item_data [ field ] = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_trending_progress ( field = Query ( None ), n = 5 , duration = 'currently' , dois = Query ( None ), mode = 'publication' , id = None , session = Depends ( get_session )) Return the trending progress over time for a given field. It will either use the top n publications or a given doi list. field : list of strings with one of the following values: 'score' (default), 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'mean_age', 'mean_length', 'mean_questions', 'mean_exclamations', 'mean_bot_rating', 'projected_change', 'trending', 'ema', 'kama', 'ker', 'mean_score', 'stddev' n : if no dois given use the top n dois (based on the current duration) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' dois : (optional) only use the given dois mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/progress/trending\" , summary = \"Get progress from the trending bucket.\" , response_model = AmbaResponse ) def get_trending_progress ( field : Optional [ str ] = Query ( None ), n : Optional [ int ] = 5 , duration : Optional [ str ] = \"currently\" , dois : Optional [ List [ str ]] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Return the trending progress over time for a given field. It will either use the top n publications or a given doi list. - **field**: list of strings with one of the following values: 'score' (default), 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'mean_age', 'mean_length', 'mean_questions', 'mean_exclamations', 'mean_bot_rating', 'projected_change', 'trending', 'ema', 'kama', 'ker', 'mean_score', 'stddev' - **n**: if no dois given use the top n dois (based on the current duration) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **dois**: (optional) only use the given dois - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if not field : field = 'score' if mode == \"fieldOfStudy\" and id : dois = get_dois_for_field_of_study ( id , session , duration ) if mode == \"author\" and id : dois = get_dois_for_author ( id , session , duration ) json_compatible_item_data = get_trending_chart_data ( query_api , session , duration , field , n , dois ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }) get_tweets_discussion_data ( doi = Query ( None ), mode = 'publication' , id = None , session = Depends ( get_session )) Get the newest discussion data. doi : (optional) only use the given doi mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/tweets\" , summary = \"Get newest discussion data.\" , response_model = AmbaResponse ) def get_tweets_discussion_data ( doi : Optional [ str ] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Get the newest discussion data. - **doi**: (optional) only use the given doi - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () json_compatible_item_data = [ get_tweets ( doi = doi , session = session , id = id , mode = mode )] return { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data } get_window_progress ( field = Query ( None ), n = 5 , duration = 'currently' , dois = Query ( None ), mode = 'publication' , id = None , session = Depends ( get_session )) Return the progress over time for a given field. It will either use the top n publications or a given doi list. Data will be aggregated in windows to optimize performance. field : list of strings with one of the following values: 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score' (default), 'sentiment_raw', 'count' n : if no dois given use the top n dois (based on the current duration) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' dois : (optional) only use the given dois mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/progress/value\" , summary = \"Get progress for publications.\" , response_model = AmbaResponse ) def get_window_progress ( field : Optional [ str ] = Query ( None ), n : Optional [ int ] = 5 , duration : Optional [ str ] = \"currently\" , dois : Optional [ List [ str ]] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Return the progress over time for a given field. It will either use the top n publications or a given doi list. Data will be aggregated in windows to optimize performance. - **field**: list of strings with one of the following values: 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score' (default), 'sentiment_raw', 'count' - **n**: if no dois given use the top n dois (based on the current duration) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **dois**: (optional) only use the given dois - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if not field : field = 'score' if mode == \"fieldOfStudy\" and id : dois = get_dois_for_field_of_study ( id , session , duration ) if mode == \"author\" and id : dois = get_dois_for_author ( id , session , duration ) json_compatible_item_data = get_window_chart_data ( query_api , session , duration , field , n , dois ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"stats"},{"location":"routers/stats_ref/#routers.stats.get_count_total_tweets","text":"Get total tweet count. doi : (optional) only use the given doi mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/countTweets\" , summary = \"Get total tweet count.\" , response_model = AmbaResponse ) def get_count_total_tweets ( doi : Optional [ str ] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Get total tweet count. - **doi**: (optional) only use the given doi - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () json_compatible_item_data = get_total_tweet_count ( doi = doi , session = session , id = id , mode = mode ) return { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }","title":"get_count_total_tweets()"},{"location":"routers/stats_ref/#routers.stats.get_count_tweet_author","text":"Get total tweet author count. doi : (optional) only use the given doi mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/countTweetAuthors\" , summary = \"Get total tweet author count.\" , response_model = AmbaResponse ) def get_count_tweet_author ( doi : Optional [ str ] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Get total tweet author count. - **doi**: (optional) only use the given doi - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () json_compatible_item_data = get_tweet_author_count ( doi = doi , session = session , id = id , mode = mode ) return { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }","title":"get_count_tweet_author()"},{"location":"routers/stats_ref/#routers.stats.get_numbers","text":"Query statistical numbers for publications. fields : list of strings with one of the following values, 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score', 'sentiment_raw', \"count\" (default) dois : (optional) only use the given dois duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/numbers\" , summary = \"Get statistical numbers.\" , response_model = AmbaResponse ) def get_numbers ( fields : Optional [ List [ str ]] = Query ( None ), dois : Optional [ List [ str ]] = Query ( None ), duration : str = \"currently\" , mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Query statistical numbers for publications. - **fields**: list of strings with one of the following values, 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score', 'sentiment_raw', \"count\" (default) - **dois**: (optional) only use the given dois - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if mode == \"fieldOfStudy\" and id : dois = get_dois_for_field_of_study ( id , session , duration ) if mode == \"author\" and id : dois = get_dois_for_author ( id , session , duration ) if not fields : fields = [ 'count' ] json_compatible_item_data = get_numbers_influx ( query_api = query_api , dois = dois , duration = duration , fields = fields ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_numbers()"},{"location":"routers/stats_ref/#routers.stats.get_profile_information","text":"Return profile information meaning it will not only return the value of the doi, author or field of study but the avg, min and max to compare against. dois : (optional) only use the given dois duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/profile\" , summary = \"Get top profile information.\" , response_model = AmbaResponse ) def get_profile_information ( doi : Optional [ str ] = Query ( None ), duration : Optional [ str ] = \"currently\" , mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Return profile information meaning it will not only return the value of the doi, author or field of study but the avg, min and max to compare against. - **dois**: (optional) only use the given dois - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if ( mode == \"publication\" and not doi ) or ( mode == \"fieldOfStudy\" and not id ) or ( mode == \"author\" and not id ): raise HTTPException ( status_code = 404 , detail = \"Missing data.\" ) doi_info = { 'publication' : get_profile_information_for_doi ( session , doi , id , mode , duration ) } if mode == \"publication\" and doi and doi_info : doi_info [ 'publication' ][ 'doi' ] = doi if mode == \"fieldOfStudy\" and id and doi_info : doi_info [ 'publication' ][ 'doi' ] = retrieve_field_of_study ( session , id )[ 'fields_of_study' ] if mode == \"author\" and id and doi_info : doi_info [ 'publication' ][ 'doi' ] = retrieve_author ( session , id )[ 'author' ] avg_info = get_profile_information_avg ( session , duration ) if doi_info and avg_info : json_compatible_item_data = jsonable_encoder ({ ** doi_info , ** avg_info }) else : json_compatible_item_data = {} return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_profile_information()"},{"location":"routers/stats_ref/#routers.stats.get_session","text":"get/create a session Source code in routers/stats.py def get_session (): \"\"\" get/create a session \"\"\" session = SessionLocal () try : yield session finally : session . close ()","title":"get_session()"},{"location":"routers/stats_ref/#routers.stats.get_top_percentage_values","text":"Query accumulated top data numbers for publications with a percentage as well as a min percentage to filter out rare items. This query does not have a duration and will always return data collected over all time. fields : list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) doi : (optional) only use the given doi limit : (optional, 10) limits the result min_percentage : (optional, 1) limits the results to only items that have a higher or equal percentage Source code in routers/stats.py @router . get ( \"/top/percentages\" , summary = \"Get top numbers with percentage.\" , response_model = AmbaResponse ) def get_top_percentage_values ( fields : Optional [ List [ str ]] = Query ( None ), doi : Optional [ str ] = None , limit : int = 10 , min_percentage : float = 1 , session : Session = Depends ( get_session )): \"\"\" Query accumulated top data numbers for publications with a percentage as well as a min percentage to filter out rare items. This query does not have a duration and will always return data collected over all time. - **fields**: list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) - **doi**: (optional) only use the given doi - **limit**: (optional, 10) limits the result - **min_percentage**: (optional, 1) limits the results to only items that have a higher or equal percentage \"\"\" start = time . time () if not fields : fields = [ 'lang' ] json_compatible_item_data = {} for field in fields : item = get_discussion_data_list_with_percentage ( session = session , doi = doi , limit = limit , min_percentage = min_percentage , dd_type = field ) json_compatible_item_data [ field ] = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_top_percentage_values()"},{"location":"routers/stats_ref/#routers.stats.get_top_values","text":"Query accumulated top data numbers for publications. This query does not have a duration and will always return data collected over all time. fields : list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) doi : (optional) only use the given doi limit : (optional, 10) limits the result mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/top\" , summary = \"Get top numbers.\" , response_model = AmbaResponse ) def get_top_values ( fields : Optional [ List [ str ]] = Query ( None ), doi : Optional [ str ] = None , limit : int = 10 , mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Query accumulated top data numbers for publications. This query does not have a duration and will always return data collected over all time. - **fields**: list of strings with one of the following values, 'entity', 'hashtag', 'lang', 'location', 'name', 'source', 'tweet_type', 'word' (default) - **doi**: (optional) only use the given doi - **limit**: (optional, 10) limits the result - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if not fields : fields = [ 'word' ] json_compatible_item_data = {} for field in fields : item = get_discussion_data_list ( session = session , doi = doi , limit = limit , dd_type = field , id = id , mode = mode ) json_compatible_item_data [ field ] = jsonable_encoder ( item ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_top_values()"},{"location":"routers/stats_ref/#routers.stats.get_trending_progress","text":"Return the trending progress over time for a given field. It will either use the top n publications or a given doi list. field : list of strings with one of the following values: 'score' (default), 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'mean_age', 'mean_length', 'mean_questions', 'mean_exclamations', 'mean_bot_rating', 'projected_change', 'trending', 'ema', 'kama', 'ker', 'mean_score', 'stddev' n : if no dois given use the top n dois (based on the current duration) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' dois : (optional) only use the given dois mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/progress/trending\" , summary = \"Get progress from the trending bucket.\" , response_model = AmbaResponse ) def get_trending_progress ( field : Optional [ str ] = Query ( None ), n : Optional [ int ] = 5 , duration : Optional [ str ] = \"currently\" , dois : Optional [ List [ str ]] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Return the trending progress over time for a given field. It will either use the top n publications or a given doi list. - **field**: list of strings with one of the following values: 'score' (default), 'count', 'mean_sentiment', 'sum_followers', 'abstract_difference', 'mean_age', 'mean_length', 'mean_questions', 'mean_exclamations', 'mean_bot_rating', 'projected_change', 'trending', 'ema', 'kama', 'ker', 'mean_score', 'stddev' - **n**: if no dois given use the top n dois (based on the current duration) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **dois**: (optional) only use the given dois - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if not field : field = 'score' if mode == \"fieldOfStudy\" and id : dois = get_dois_for_field_of_study ( id , session , duration ) if mode == \"author\" and id : dois = get_dois_for_author ( id , session , duration ) json_compatible_item_data = get_trending_chart_data ( query_api , session , duration , field , n , dois ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_trending_progress()"},{"location":"routers/stats_ref/#routers.stats.get_tweets_discussion_data","text":"Get the newest discussion data. doi : (optional) only use the given doi mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/tweets\" , summary = \"Get newest discussion data.\" , response_model = AmbaResponse ) def get_tweets_discussion_data ( doi : Optional [ str ] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Get the newest discussion data. - **doi**: (optional) only use the given doi - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () json_compatible_item_data = [ get_tweets ( doi = doi , session = session , id = id , mode = mode )] return { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data }","title":"get_tweets_discussion_data()"},{"location":"routers/stats_ref/#routers.stats.get_window_progress","text":"Return the progress over time for a given field. It will either use the top n publications or a given doi list. Data will be aggregated in windows to optimize performance. field : list of strings with one of the following values: 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score' (default), 'sentiment_raw', 'count' n : if no dois given use the top n dois (based on the current duration) duration : the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' dois : (optional) only use the given dois mode : what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' id : needed for 'fieldOfStudy' or 'author' mode, the id of the entity Source code in routers/stats.py @router . get ( \"/progress/value\" , summary = \"Get progress for publications.\" , response_model = AmbaResponse ) def get_window_progress ( field : Optional [ str ] = Query ( None ), n : Optional [ int ] = 5 , duration : Optional [ str ] = \"currently\" , dois : Optional [ List [ str ]] = Query ( None ), mode : str = \"publication\" , id : int = None , session : Session = Depends ( get_session )): \"\"\" Return the progress over time for a given field. It will either use the top n publications or a given doi list. Data will be aggregated in windows to optimize performance. - **field**: list of strings with one of the following values: 'bot_rating', 'contains_abstract_raw', 'exclamations', 'followers', 'length', 'questions', 'score' (default), 'sentiment_raw', 'count' - **n**: if no dois given use the top n dois (based on the current duration) - **duration**: the duration of data that should be queried, 'currently' (default), 'today', 'week', 'month', 'year' - **dois**: (optional) only use the given dois - **mode**: what mode should be used, can be: 'publication' (default), 'fieldOfStudy' or 'author' - **id**: needed for 'fieldOfStudy' or 'author' mode, the id of the entity \"\"\" start = time . time () if not field : field = 'score' if mode == \"fieldOfStudy\" and id : dois = get_dois_for_field_of_study ( id , session , duration ) if mode == \"author\" and id : dois = get_dois_for_author ( id , session , duration ) json_compatible_item_data = get_window_chart_data ( query_api , session , duration , field , n , dois ) return JSONResponse ( content = { \"time\" : round (( time . time () - start ) * 1000 ), \"results\" : json_compatible_item_data })","title":"get_window_progress()"}]}